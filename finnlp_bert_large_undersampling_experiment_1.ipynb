{"cells":[{"cell_type":"code","execution_count":null,"id":"4561e38a-ddd6-4220-9478-6c1977c3800d","metadata":{},"outputs":[],"source":["import pandas as pd\n","import transformers\n","import torch\n","import random\n","import pandas as pd\n","import random\n","import string\n","import numpy as np\n","import unidecode\n","from unidecode import unidecode\n","from wordcloud import STOPWORDS\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n","from torch.utils.data import TensorDataset\n","from tqdm.notebook import tqdm\n","from transformers import AutoModel, AutoTokenizer, BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, PreTrainedTokenizerFast\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn import metrics\n","import tensorflow as tf\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import torch\n","transformers.logging.set_verbosity_debug()\n","from loguru import logger\n","logger.add(\"logging/finnlp_bert_large_undersampling_experiment_1.log\", rotation=\"500 MB\")"]},{"cell_type":"code","execution_count":16,"id":"447f7c43-6908-40c6-813a-bf04800038a0","metadata":{},"outputs":[],"source":["BATCH_SIZE = 15"]},{"cell_type":"code","execution_count":17,"id":"3bc27f5b-935f-47dd-84bd-25349c58d72c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-01 20:10:23.414 | DEBUG    | __main__:<module>:1 - <<<<<<<<<< INICIOU >>>>>>>>>>>\n"]}],"source":["logger.debug(\"<<<<<<<<<< INICIOU >>>>>>>>>>>\")\n","brc = pd.read_csv(\"Banking_Regulation_Corpora_BRC_anonymous.csv\" ,encoding=\"utf-8\", low_memory=False, sep=\";\")\n","data_relevant = brc[brc['class'] == 1]\n","data_irrelevant = brc[brc['class'] == 0]"]},{"cell_type":"code","execution_count":18,"id":"bef4477a-a086-4590-b767-e9d6d6e54328","metadata":{},"outputs":[{"data":{"text/plain":["class                   7846\n","department              7846\n","entry_date              7846\n","general_id              7846\n","normative_identifier    7846\n","publication_date        7846\n","regulatory_authority    7846\n","subject                 7846\n","subject_length          7846\n","subject_unique_words    7846\n","subject_words           7846\n","text                    7846\n","text_length             7846\n","text_unique_words       7846\n","text_words              7846\n","type                    7846\n","unique_document_id      7846\n","url                     7846\n","dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant.count()"]},{"cell_type":"code","execution_count":19,"id":"c81c28dc-335c-4847-8e80-91720c9d523c","metadata":{},"outputs":[{"data":{"text/plain":["class                   7714\n","department              7714\n","entry_date              7714\n","general_id              7714\n","normative_identifier    7714\n","publication_date        7714\n","regulatory_authority    7714\n","subject                 7714\n","subject_length          7714\n","subject_unique_words    7714\n","subject_words           7714\n","text                    7714\n","text_length             7714\n","text_unique_words       7714\n","text_words              7714\n","type                    7714\n","unique_document_id      7714\n","url                     7714\n","dtype: int64"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant = data_relevant[data_relevant.text_words >= 50]\n","data_relevant.count()"]},{"cell_type":"code","execution_count":20,"id":"748ef113-c0e4-4d88-adac-770a079c5f03","metadata":{},"outputs":[],"source":["data_relevant['class'] = data_relevant['class'].astype(str)"]},{"cell_type":"code","execution_count":21,"id":"6bf25605-9cf5-48a2-ace5-6b02f413342c","metadata":{},"outputs":[],"source":["data_relevant = data_relevant.rename(columns={\"class\":\"label\"})"]},{"cell_type":"code","execution_count":22,"id":"5718b997-51e1-4b46-a836-c55c73f1a254","metadata":{},"outputs":[{"data":{"text/plain":["label                   7714\n","department              7714\n","entry_date              7714\n","general_id              7714\n","normative_identifier    7714\n","publication_date        7714\n","regulatory_authority    7714\n","subject                 7714\n","subject_length          7714\n","subject_unique_words    7714\n","subject_words           7714\n","text                    7714\n","text_length             7714\n","text_unique_words       7714\n","text_words              7714\n","type                    7714\n","unique_document_id      7714\n","url                     7714\n","dtype: int64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant.count()"]},{"cell_type":"code","execution_count":23,"id":"bb41ca7d-a5c1-483a-af26-d2d1dedbd6e1","metadata":{},"outputs":[{"data":{"text/plain":["class                   54018\n","department              54018\n","entry_date              54018\n","general_id              54018\n","normative_identifier    54018\n","publication_date        54018\n","regulatory_authority    54018\n","subject                 54018\n","subject_length          54018\n","subject_unique_words    54018\n","subject_words           54018\n","text                    54018\n","text_length             54018\n","text_unique_words       54018\n","text_words              54018\n","type                    54018\n","unique_document_id      54018\n","url                     54018\n","dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant.count()"]},{"cell_type":"code","execution_count":24,"id":"20e3f3d7-28e4-452d-a261-49e949aa542a","metadata":{},"outputs":[{"data":{"text/plain":["class                   53122\n","department              53122\n","entry_date              53122\n","general_id              53122\n","normative_identifier    53122\n","publication_date        53122\n","regulatory_authority    53122\n","subject                 53122\n","subject_length          53122\n","subject_unique_words    53122\n","subject_words           53122\n","text                    53122\n","text_length             53122\n","text_unique_words       53122\n","text_words              53122\n","type                    53122\n","unique_document_id      53122\n","url                     53122\n","dtype: int64"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant = data_irrelevant[data_irrelevant.text_words >= 50]\n","data_irrelevant.count()"]},{"cell_type":"code","execution_count":25,"id":"a5aecb55-4127-46fd-97cc-764221fac2b6","metadata":{},"outputs":[],"source":["data_irrelevant['class'] = data_irrelevant['class'].astype(str)"]},{"cell_type":"code","execution_count":26,"id":"3dbd3087-f3cb-45bc-b86e-3a8abd6c3f6e","metadata":{},"outputs":[],"source":["data_irrelevant = data_irrelevant.rename(columns={\"class\":\"label\"})"]},{"cell_type":"code","execution_count":27,"id":"457df4a5-c1f4-4269-beb3-fe4e1a3672ec","metadata":{},"outputs":[{"data":{"text/plain":["label                   53122\n","department              53122\n","entry_date              53122\n","general_id              53122\n","normative_identifier    53122\n","publication_date        53122\n","regulatory_authority    53122\n","subject                 53122\n","subject_length          53122\n","subject_unique_words    53122\n","subject_words           53122\n","text                    53122\n","text_length             53122\n","text_unique_words       53122\n","text_words              53122\n","type                    53122\n","unique_document_id      53122\n","url                     53122\n","dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant.count()"]},{"cell_type":"code","execution_count":28,"id":"8ee85a14-d6fc-439e-801c-54f1179a685d","metadata":{},"outputs":[],"source":["class Model_BERT():\n","    \n","    def model_path_def(self, name_model):\n","        if name_model == \"BERTIMBAU_LARGE\":\n","            model_path = MODEL_PATH\n","        elif name_model == \"XXX\":\n","            model_path = MODEL_PATH_NEW\n","        else:\n","            print(\"Nome de modelo inválido\")\n","            model_path = \"None\"\n","            \n","        return model_path\n","\n","    def tokenizer_model(self, model_path, df, token):\n","        tokenizer = BertTokenizer.from_pretrained(BERTIMBAU_TOKENIZER, do_lower_case=True)\n","\n","        # Tokenizing the training data\n","        encoded_data_train = tokenizer.batch_encode_plus(\n","            df[df.data_type=='train'].new_content.tolist(), \n","            add_special_tokens=True, \n","            return_attention_mask=True, \n","            padding=True, \n","            max_length=token, \n","            return_tensors='pt',\n","            truncation=True\n","        )\n","\n","        # Tokenizing test data\n","        encoded_data_val = tokenizer.batch_encode_plus(\n","            df[df.data_type=='val'].new_content.tolist(), \n","            add_special_tokens=True, \n","            return_attention_mask=True, \n","            padding=True,\n","            max_length=token, \n","            return_tensors='pt',\n","            truncation=True\n","        )\n","\n","\n","        input_ids_train = encoded_data_train['input_ids']\n","        attention_masks_train = encoded_data_train['attention_mask']\n","        labels_train = torch.tensor(df[df.data_type=='train'].label_num.values)\n","\n","        input_ids_val = encoded_data_val['input_ids']\n","        attention_masks_val = encoded_data_val['attention_mask']\n","        labels_val = torch.tensor(df[df.data_type=='val'].label_num.values)\n","\n","        dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","        dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","        \n","        return(dataset_train, dataset_val)\n","\n","    def setup_model(self, model_path, dataset_train, dataset_val, epochs):\n","        model = BertForSequenceClassification.from_pretrained(model_path,\n","                                                              num_labels=len(LABEL_DICT),\n","                                                              output_attentions=False,\n","                                                              output_hidden_states=False)\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model.to(device)\n","        batch_size = BATCH_SIZE\n","        dataloader_train = DataLoader(dataset_train, \n","                                      sampler=RandomSampler(dataset_train), \n","                                      batch_size=batch_size)\n","        dataloader_validation = DataLoader(dataset_val, \n","                                           sampler=SequentialSampler(dataset_val), \n","                                           batch_size=batch_size)\n","        optimizer = AdamW(model.parameters(),\n","                          lr=1e-5, \n","                          eps=1e-8)\n","\n","        scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                    num_warmup_steps=100,\n","                                                    num_training_steps=len(dataloader_train)*epochs)\n","        return(model, dataloader_train, dataloader_validation, epochs, scheduler, optimizer, device)\n","\n","\n","    def f1_score_func(self, preds, labels):\n","        preds_flat = np.argmax(preds, axis=1).flatten()\n","        labels_flat = labels.flatten()\n","        \n","        scr = f1_score(labels_flat, preds_flat, average='binary')\n","        logger.info(f\"f1_score_binary: {scr}\")\n","        return scr\n","\n","    def accuracy_per_class(self, preds, labels):\n","        label_dict_inverse = {v: k for k, v in LABEL_DICT.items()}\n","        \n","\n","        preds_flat = np.argmax(preds, axis=1).flatten()\n","        labels_flat = labels.flatten()\n","\n","        for label in np.unique(labels_flat):\n","            y_preds = preds_flat[labels_flat==label]\n","            y_true = labels_flat[labels_flat==label]\n","            print(f'Class: {label_dict_inverse[label]}')\n","            print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}')\n","            print(f'% Accuracy: {len(y_preds[y_preds==label])/len(y_true)}\\n')\n","            logger.info(f'Class: {label_dict_inverse[label]}')\n","            logger.info(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}')\n","            logger.info(f'% Accuracy: {len(y_preds[y_preds==label])/len(y_true)}\\n')\n","        \n","    def evaluate(self, model, dataloader_val, device):\n","\n","        model.eval()\n","\n","        loss_val_total = 0\n","        predictions, true_vals = [], []\n","\n","        for batch in dataloader_val:\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            with torch.no_grad():        \n","                outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            loss_val_total += loss.item()\n","\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = inputs['labels'].cpu().numpy()\n","            predictions.append(logits)\n","            true_vals.append(label_ids)\n","\n","        loss_val_avg = loss_val_total/len(dataloader_val) \n","\n","        predictions = np.concatenate(predictions, axis=0)\n","        true_vals = np.concatenate(true_vals, axis=0)\n","\n","        logger.info(f\"loss_val_avg, predictions, true_vals: {loss_val_avg}, {predictions}, {true_vals}\")\n","\n","        return loss_val_avg, predictions, true_vals\n","\n","    def results(self, model_path, model_name, epochs, dataloader_validation, device, token):\n","        model = BertForSequenceClassification.from_pretrained(model_path,\n","                                                              num_labels=len(LABEL_DICT),\n","                                                              output_attentions=False,\n","                                                              output_hidden_states=False)\n","\n","        model.to(device)\n","\n","        model.load_state_dict(torch.load(f'{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epochs}.model', map_location=torch.device('cpu')))\n","\n","        _, predictions, true_vals = Model_BERT().evaluate(model, dataloader_validation, device)\n","        Model_BERT().accuracy_per_class(predictions, true_vals)\n","        from sklearn import metrics\n","        preds_flat = np.argmax(predictions, axis=1).flatten()\n","        metrics_report = metrics.classification_report(true_vals,preds_flat, output_dict=True)\n","        logger.info(metrics_report)\n","                \n","        return metrics_report\n","    \n","\n","    def training_model(self, model, model_name, dataloader_train, dataloader_validation, epochs, scheduler, optimizer, device, token):\n","        seed_val = 1\n","        random.seed(seed_val)\n","        np.random.seed(seed_val)\n","        torch.manual_seed(seed_val)\n","        torch.cuda.manual_seed_all(seed_val)\n","        epoch_array = []\n","        f1_array = []\n","        train_loss_array = []\n","        val_loss_array = []\n","\n","        for epoch in tqdm(range(1, epochs+1)):\n","\n","            model.train()\n","\n","            loss_train_total = 0\n","\n","            progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","            for batch in progress_bar:\n","\n","                model.zero_grad()\n","\n","                batch = tuple(b.to(device) for b in batch)\n","\n","                inputs = {'input_ids':      batch[0],\n","                          'attention_mask': batch[1],\n","                          'labels':         batch[2],\n","                         }       \n","\n","                outputs = model(**inputs)\n","\n","                loss = outputs[0]\n","                loss_train_total += loss.item()\n","                loss.backward()\n","\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","                optimizer.step()\n","                scheduler.step()\n","\n","                progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","\n","            torch.save(model.state_dict(),f'{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epoch}.model')\n","            model.save_pretrained(f\"{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epoch}\")\n","            tqdm.write(f'\\nEpoch {epoch}')\n","            print(f'\\nEpoch {epoch}')\n","            logger.info(f'\\nEpoch {epoch}')\n","\n","            loss_train_avg = loss_train_total/len(dataloader_train)            \n","            tqdm.write(f'Training loss: {loss_train_avg}')\n","            logger.info(f'Training loss: {loss_train_avg}')\n","\n","            val_loss, predictions, true_vals = Model_BERT().evaluate(model, dataloader_validation, device)\n","            val_f1 = Model_BERT().f1_score_func(predictions, true_vals)\n","            tqdm.write(f'Validation loss: {val_loss}')\n","            print(f'Validation loss: {val_loss}')\n","            logger.info(f'Validation loss: {val_loss}')\n","            \n","            tqdm.write(f'F1 Score (Weighted/Binary): {val_f1}')\n","            print(f'F1 Score (Weighted/Binary): {val_f1}')\n","            logger.info(f'F1 Score (Weighted/Binary): {val_f1}')\n","            \n","            epoch_array.append(epoch)\n","            f1_array.append(val_f1)\n","            val_loss_array.append(val_loss)\n","            train_loss_array.append(loss_train_avg)\n","\n","        return(epoch_array, f1_array, val_loss_array, train_loss_array)\n","    \n","    def read_df(self, df):\n","        df['label_num'] = df.label.replace(LABEL_DICT)\n","        \n","        X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n","                                                  df.label_num.values, \n","                                                  test_size=0.4, \n","                                                  random_state=42, \n","                                                  stratify=df.label.values)\n","        df['data_type'] = ['not_set']*df.shape[0]\n","        df.loc[X_train, 'data_type'] = 'train'\n","        df.loc[X_val, 'data_type'] = 'val'\n","        \n","        return(df)\n","\n","    def call_setup(self, model_name, df, token, epochs):\n","        df = Model_BERT().read_df(df)\n","        model_path = Model_BERT().model_path_def(model_name)\n","        print(model_path)\n","        dataset_train, dataset_val = Model_BERT().tokenizer_model(model_path, df, token)\n","        model, dataloader_train, dataloader_val, epochs, scheduler, optimizer, device = Model_BERT().setup_model(model_path, dataset_train, dataset_val, epochs)\n","        epoch_array, f1_array, val_loss_array, train_loss_array = Model_BERT().training_model(model, model_name, dataloader_train, dataloader_val, epochs, scheduler, optimizer, device, token)\n","        df_performa = pd.DataFrame()\n","        df_performa[\"epoch\"] = epoch_array\n","        df_performa[\"f1\"] = f1_array\n","        df_performa[\"val_loss\"] = val_loss_array\n","        df_performa[\"train_loss\"] = train_loss_array\n","        metrics_report = Model_BERT().results(model_path,model_name,epochs,dataloader_val, device, token)\n","        logger.info(f'Metric Report Call Setup: {metrics_report}')\n","        \n","        return metrics_report, df_performa"]},{"cell_type":"code","execution_count":29,"id":"1df25eaa-1685-4362-850f-96300d104939","metadata":{},"outputs":[],"source":["departments = ['DPT_25', 'DPT_3', 'DPT_2', 'DPT_9', 'DPT_5', 'DPT_16']"]},{"cell_type":"code","execution_count":30,"id":"30b79f7d-153f-4839-a04f-3793c36bd1b7","metadata":{},"outputs":[],"source":["def cleaning(df,column):\n","    # Remove urls\n","    df.loc[:,column] = df[column].replace(r'https?:\\/\\/.*?[\\s+]', ' ', regex=True)\n","    # Remove urls without https?\n","    df.loc[:,column] = df[column].replace(r'www.*?[\\s+]', ' ', regex=True)\n","    # Remove email address\n","    df.loc[:,column] = df[column].replace(r'(?P<email_address>[\\w\\.-]+@[\\w\\.-]+\\.[\\w]+)', ' ', regex=True)\n","    \n","    df.loc[:,column] = df[column].str.replace('º',' ')\n","    df.loc[:,column] = df[column].str.replace('ª',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('1',' ')\n","    df.loc[:,column] = df[column].str.replace('2',' ')\n","    df.loc[:,column] = df[column].str.replace('3',' ')\n","    df.loc[:,column] = df[column].str.replace('4',' ')\n","    df.loc[:,column] = df[column].str.replace('5',' ')\n","    df.loc[:,column] = df[column].str.replace('6',' ')\n","    df.loc[:,column] = df[column].str.replace('7',' ')\n","    df.loc[:,column] = df[column].str.replace('8',' ')\n","    df.loc[:,column] = df[column].str.replace('9',' ')\n","    df.loc[:,column] = df[column].str.replace('0',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('/',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('\\r',' ')\n","    df.loc[:,column] = df[column].str.replace('\\n',' ')\n","    df.loc[:,column] = df[column].str.replace('\\t',' ')\n","    df.loc[:,column] = df[column].str.replace('\\\\',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('-',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('–',' ')\n","    df.loc[:,column] = df[column].str.replace('“',' ')\n","    df.loc[:,column] = df[column].str.replace('”',' ')\n","    df.loc[:,column] = df[column].str.replace('’',' ')\n","    df.loc[:,column] = df[column].str.replace('_',' ')\n","    df.loc[:,column] = df[column].str.replace('.',' ')\n","    df.loc[:,column] = df[column].str.replace(',',' ')\n","    df.loc[:,column] = df[column].str.replace('|',' ')\n","    df.loc[:,column] = df[column].str.replace('=',' ')\n","    df.loc[:,column] = df[column].str.replace('@',' ')\n","    df.loc[:,column] = df[column].str.replace('$',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('°',' ')\n","    df.loc[:,column] = df[column].str.replace('§',' ')\n","    df.loc[:,column] = df[column].str.replace('•',' ')\n","    df.loc[:,column] = df[column].str.replace('▪',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('%',' ')\n","    df.loc[:,column] = df[column].str.replace('&',' ')\n","    df.loc[:,column] = df[column].str.replace('*',' ')\n","    df.loc[:,column] = df[column].str.replace('+',' ')\n","    df.loc[:,column] = df[column].str.replace(':',' ')\n","    df.loc[:,column] = df[column].str.replace(';',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('!',' ')\n","    df.loc[:,column] = df[column].str.replace('?',' ')\n","    df.loc[:,column] = df[column].str.replace('#',' ')\n","    df.loc[:,column] = df[column].str.replace('\\'',' ')\n","    df.loc[:,column] = df[column].str.replace('\"',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('<',' ')\n","    df.loc[:,column] = df[column].str.replace('>',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('(',' ')\n","    df.loc[:,column] = df[column].str.replace(')',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('{',' ')\n","    df.loc[:,column] = df[column].str.replace('}',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('[',' ')\n","    df.loc[:,column] = df[column].str.replace(']',' ')\n","\n","    # Remove the same character repeated more than twice\n","    df.loc[:,column] = df[column].replace(r'([a-z])\\1{2,}', ' ', regex=True)\n","    \n","    # To replace more than one white space by only one white space\n","    df.loc[:,column] = df[column].replace(r'\\s+', ' ', regex=True)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"801009fb-5671-47d5-bc5b-167696fb3208","metadata":{"scrolled":true},"outputs":[],"source":["for department in departments:\n","\n","    total_relevant_documents_of_the_board = data_relevant[data_relevant.department == department].shape[0]\n","    logger.info(f\"total_relevant_documents_of_the_board: {total_relevant_documents_of_the_board} - {department}\")\n","    logger.info(f\"Total irrelevant documents of the department: {data_irrelevant[data_irrelevant.department == department].shape[0]} - {department}\")\n","    \n","    data_relevant_board = data_relevant[data_relevant.department == department]\n","    logger.info(f\"data_relevant_board: {data_relevant_board.shape} - {department}\")\n","    \n","    # The total documents of the relevant class (total_relevant_documents_of_the_board) is use to get the first documents in the irrelevant class.\n","    data_irrelevant_board = data_irrelevant[data_irrelevant.department == department][:total_relevant_documents_of_the_board]\n","    logger.info(f\"data_irrelevant_board: {data_irrelevant_board.shape} - {department}\")\n","\n","    df_ace_modelagem = pd.concat([data_irrelevant_board, data_relevant_board])\n","    \n","    logger.debug(f\"Department: {department}\")\n","    df_modelagem = df_ace_modelagem[df_ace_modelagem.department == department]\n","\n","    df_modelagem = df_modelagem.dropna()\n","    df_modelagem = df_modelagem.reset_index(drop=True)\n","    df_modelagem = df_modelagem.rename(columns={\"text\":\"content\"})\n","\n","    df_modelagem = cleaning(df_modelagem,\"content\")\n","\n","    new_content = []\n","    for texto in df_modelagem.content:\n","        new_content.append(texto.replace(\"[BUSINESS NEED]\", \"\"))\n","    df_modelagem[\"new_content\"] = new_content\n","    \n","    LABEL_DICT = {'0': 0, '1': 1}\n","\n","    MODEL_SAVE_PATH = \"notebooks/testes/escoragem\"\n","    BERTIMBAU_LARGE = \"dataset/bert-large-portuguese-cased\"\n","    BERTIMBAU_TOKENIZER = \"tokenizer/BERTimbau_Tokenizer\"\n","\n","    MODEL_PATH = BERTIMBAU_LARGE\n","    MODEL_PATH_NEW = BERTIMBAU_LARGE\n","\n","    tokenizer = BertTokenizer.from_pretrained(BERTIMBAU_TOKENIZER, do_lower_case=True)\n","\n","    logger.debug(f\"Department count samples: {df_modelagem.count()}\")\n","    logger.debug(f\"Department count samples class 1: {df_modelagem[df_modelagem.label == '1'].count()}\")\n","    logger.debug(f\"Department count samples class 0: {df_modelagem[df_modelagem.label == '0'].count()}\")\n","    \n","\n","    Model_BERT().call_setup(\"BERTIMBAU_LARGE\", df_modelagem, 512, 5)"]},{"cell_type":"markdown","id":"21a56f84","metadata":{},"source":["<h2>The output result is in the next cell. It was copied from the log file.</h2>"]},{"cell_type":"code","execution_count":null,"id":"30079640","metadata":{},"outputs":[],"source":["# 2023-10-16 11:18:06.563 | DEBUG    | __main__:<module>:1 - <<<<<<<<<< INICIOU >>>>>>>>>>>\n","# 2023-10-16 11:18:16.831 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 819 - DPT_25\n","# 2023-10-16 11:18:16.838 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 4051 - DPT_25\n","# 2023-10-16 11:18:16.840 | INFO     | __main__:<module>:8 - data_relevant_board: (819, 18) - DPT_25\n","# 2023-10-16 11:18:16.845 | INFO     | __main__:<module>:12 - data_irrelevant_board: (819, 18) - DPT_25\n","# 2023-10-16 11:18:16.849 | DEBUG    | __main__:<module>:18 - Department: DPT_25\n","# 2023-10-16 11:18:20.221 | DEBUG    | __main__:<module>:53 - Department count samples: label                   1638\n","# department              1638\n","# entry_date              1638\n","# general_id              1638\n","# normative_identifier    1638\n","# publication_date        1638\n","# regulatory_authority    1638\n","# subject                 1638\n","# subject_length          1638\n","# subject_unique_words    1638\n","# subject_words           1638\n","# content                 1638\n","# text_length             1638\n","# text_unique_words       1638\n","# text_words              1638\n","# type                    1638\n","# unique_document_id      1638\n","# url                     1638\n","# new_content             1638\n","# dtype: int64\n","# 2023-10-16 11:18:20.225 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   819\n","# department              819\n","# entry_date              819\n","# general_id              819\n","# normative_identifier    819\n","# publication_date        819\n","# regulatory_authority    819\n","# subject                 819\n","# subject_length          819\n","# subject_unique_words    819\n","# subject_words           819\n","# content                 819\n","# text_length             819\n","# text_unique_words       819\n","# text_words              819\n","# type                    819\n","# unique_document_id      819\n","# url                     819\n","# new_content             819\n","# dtype: int64\n","# 2023-10-16 11:18:20.229 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   819\n","# department              819\n","# entry_date              819\n","# general_id              819\n","# normative_identifier    819\n","# publication_date        819\n","# regulatory_authority    819\n","# subject                 819\n","# subject_length          819\n","# subject_unique_words    819\n","# subject_words           819\n","# content                 819\n","# text_length             819\n","# text_unique_words       819\n","# text_words              819\n","# type                    819\n","# unique_document_id      819\n","# url                     819\n","# new_content             819\n","# dtype: int64\n","# 2023-10-16 11:21:02.123 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 11:21:02.124 | INFO     | __main__:training_model:214 - Training loss: 0.5665207931941206\n","# 2023-10-16 11:21:21.453 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.44458932463418355, [[-0.56939614  1.0990589 ]\n","\n","# 2023-10-16 11:21:21.456 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8\n","# 2023-10-16 11:21:21.458 | INFO     | __main__:training_model:220 - Validation loss: 0.44458932463418355\n","# 2023-10-16 11:21:21.459 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8\n","# 2023-10-16 11:23:00.190 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 11:23:00.193 | INFO     | __main__:training_model:214 - Training loss: 0.42923686405022937\n","# 2023-10-16 11:23:19.594 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.38967092453756114, [[-1.2045168   1.2743595 ]\n","\n","# 2023-10-16 11:23:19.598 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8215488215488216\n","# 2023-10-16 11:23:19.600 | INFO     | __main__:training_model:220 - Validation loss: 0.38967092453756114\n","# 2023-10-16 11:23:19.601 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8215488215488216\n","# 2023-10-16 11:24:58.164 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 11:24:58.166 | INFO     | __main__:training_model:214 - Training loss: 0.33622951049244765\n","# 2023-10-16 11:25:17.584 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3164817977019332, [[-1.8283786   1.8242496 ]\n","\n","# 2023-10-16 11:25:17.588 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8760064412238326\n","# 2023-10-16 11:25:17.589 | INFO     | __main__:training_model:220 - Validation loss: 0.3164817977019332\n","# 2023-10-16 11:25:17.591 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8760064412238326\n","# 2023-10-16 11:26:53.750 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 11:26:53.751 | INFO     | __main__:training_model:214 - Training loss: 0.2653636721837701\n","# 2023-10-16 11:27:13.212 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3078154611655257, [[-2.4466856   2.2146797 ]\n","\n","# 2023-10-16 11:27:13.216 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8766233766233766\n","# 2023-10-16 11:27:13.217 | INFO     | __main__:training_model:220 - Validation loss: 0.3078154611655257\n","# 2023-10-16 11:27:13.218 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8766233766233766\n","# 2023-10-16 11:28:51.337 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 11:28:51.338 | INFO     | __main__:training_model:214 - Training loss: 0.20343350551345132\n","# 2023-10-16 11:29:10.781 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3046977175399661, [[-2.3351874  2.1522033]\n","\n","# 2023-10-16 11:29:10.784 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8817891373801916\n","# 2023-10-16 11:29:10.785 | INFO     | __main__:training_model:220 - Validation loss: 0.3046977175399661\n","# 2023-10-16 11:29:10.786 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8817891373801916\n","# 2023-10-16 11:29:34.677 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3046977175399661, [[-2.3351874  2.1522033]\n","\n","# 2023-10-16 11:29:34.679 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 11:29:34.680 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 306/328\n","# 2023-10-16 11:29:34.681 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.9329268292682927\n","\n","# 2023-10-16 11:29:34.682 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 11:29:34.683 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 276/328\n","# 2023-10-16 11:29:34.683 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8414634146341463\n","\n","# 2023-10-16 11:29:34.691 | INFO     | __main__:results:157 - {'0': {'precision': 0.8547486033519553, 'recall': 0.9329268292682927, 'f1-score': 0.8921282798833818, 'support': 328}, '1': {'precision': 0.9261744966442953, 'recall': 0.8414634146341463, 'f1-score': 0.8817891373801916, 'support': 328}, 'accuracy': 0.8871951219512195, 'macro avg': {'precision': 0.8904615499981253, 'recall': 0.8871951219512195, 'f1-score': 0.8869587086317867, 'support': 656}, 'weighted avg': {'precision': 0.8904615499981253, 'recall': 0.8871951219512195, 'f1-score': 0.8869587086317866, 'support': 656}}\n","# 2023-10-16 11:29:34.694 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.8547486033519553, 'recall': 0.9329268292682927, 'f1-score': 0.8921282798833818, 'support': 328}, '1': {'precision': 0.9261744966442953, 'recall': 0.8414634146341463, 'f1-score': 0.8817891373801916, 'support': 328}, 'accuracy': 0.8871951219512195, 'macro avg': {'precision': 0.8904615499981253, 'recall': 0.8871951219512195, 'f1-score': 0.8869587086317867, 'support': 656}, 'weighted avg': {'precision': 0.8904615499981253, 'recall': 0.8871951219512195, 'f1-score': 0.8869587086317866, 'support': 656}}\n","# 2023-10-16 11:29:34.701 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 688 - DPT_3\n","# 2023-10-16 11:29:34.708 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 1790 - DPT_3\n","# 2023-10-16 11:29:34.710 | INFO     | __main__:<module>:8 - data_relevant_board: (688, 18) - DPT_3\n","# 2023-10-16 11:29:34.715 | INFO     | __main__:<module>:12 - data_irrelevant_board: (688, 18) - DPT_3\n","# 2023-10-16 11:29:34.719 | DEBUG    | __main__:<module>:18 - Department: DPT_3\n","# 2023-10-16 11:29:47.921 | DEBUG    | __main__:<module>:53 - Department count samples: label                   1376\n","# department              1376\n","# entry_date              1376\n","# general_id              1376\n","# normative_identifier    1376\n","# publication_date        1376\n","# regulatory_authority    1376\n","# subject                 1376\n","# subject_length          1376\n","# subject_unique_words    1376\n","# subject_words           1376\n","# content                 1376\n","# text_length             1376\n","# text_unique_words       1376\n","# text_words              1376\n","# type                    1376\n","# unique_document_id      1376\n","# url                     1376\n","# new_content             1376\n","# dtype: int64\n","# 2023-10-16 11:29:47.926 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   688\n","# department              688\n","# entry_date              688\n","# general_id              688\n","# normative_identifier    688\n","# publication_date        688\n","# regulatory_authority    688\n","# subject                 688\n","# subject_length          688\n","# subject_unique_words    688\n","# subject_words           688\n","# content                 688\n","# text_length             688\n","# text_unique_words       688\n","# text_words              688\n","# type                    688\n","# unique_document_id      688\n","# url                     688\n","# new_content             688\n","# dtype: int64\n","# 2023-10-16 11:29:47.929 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   688\n","# department              688\n","# entry_date              688\n","# general_id              688\n","# normative_identifier    688\n","# publication_date        688\n","# regulatory_authority    688\n","# subject                 688\n","# subject_length          688\n","# subject_unique_words    688\n","# subject_words           688\n","# content                 688\n","# text_length             688\n","# text_unique_words       688\n","# text_words              688\n","# type                    688\n","# unique_document_id      688\n","# url                     688\n","# new_content             688\n","# dtype: int64\n","# 2023-10-16 11:34:42.635 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 11:34:42.637 | INFO     | __main__:training_model:214 - Training loss: 0.6929952404715798\n","# 2023-10-16 11:34:58.900 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6773132069690807, [[ 0.30348426  0.02432838]\n","\n","# 2023-10-16 11:34:58.904 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.43478260869565216\n","# 2023-10-16 11:34:58.905 | INFO     | __main__:training_model:220 - Validation loss: 0.6773132069690807\n","# 2023-10-16 11:34:58.906 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.43478260869565216\n","# 2023-10-16 11:36:22.524 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 11:36:22.525 | INFO     | __main__:training_model:214 - Training loss: 0.6551436662673951\n","# 2023-10-16 11:36:38.822 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.5856909244447142, [[ 0.08722901  0.04988722]\n","\n","# 2023-10-16 11:36:38.826 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.6975881261595547\n","# 2023-10-16 11:36:38.827 | INFO     | __main__:training_model:220 - Validation loss: 0.5856909244447142\n","# 2023-10-16 11:36:38.828 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.6975881261595547\n","# 2023-10-16 11:38:02.817 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 11:38:02.819 | INFO     | __main__:training_model:214 - Training loss: 0.49475210254842583\n","# 2023-10-16 11:38:19.126 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.4851993855995101, [[ 0.59804356 -0.36762857]\n","\n","# 2023-10-16 11:38:19.130 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.7717391304347825\n","# 2023-10-16 11:38:19.131 | INFO     | __main__:training_model:220 - Validation loss: 0.4851993855995101\n","# 2023-10-16 11:38:19.132 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.7717391304347825\n","# 2023-10-16 11:39:43.016 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 11:39:43.017 | INFO     | __main__:training_model:214 - Training loss: 0.36618411595171146\n","# 2023-10-16 11:39:59.325 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.4764693441825944, [[ 0.49186736 -0.36016956]\n","\n","# 2023-10-16 11:39:59.329 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.783050847457627\n","# 2023-10-16 11:39:59.330 | INFO     | __main__:training_model:220 - Validation loss: 0.4764693441825944\n","# 2023-10-16 11:39:59.331 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.783050847457627\n","# 2023-10-16 11:41:23.829 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 11:41:23.830 | INFO     | __main__:training_model:214 - Training loss: 0.29054132794792004\n","# 2023-10-16 11:41:40.143 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.48134107897813255, [[ 1.4834504  -0.56097406]\n","\n","# 2023-10-16 11:41:40.147 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.771266540642722\n","# 2023-10-16 11:41:40.148 | INFO     | __main__:training_model:220 - Validation loss: 0.48134107897813255\n","# 2023-10-16 11:41:40.150 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.771266540642722\n","# 2023-10-16 11:42:00.504 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.48134107897813255, [[ 1.4834504  -0.56097406]\n","\n","# 2023-10-16 11:42:00.506 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 11:42:00.507 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 226/276\n","# 2023-10-16 11:42:00.508 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8188405797101449\n","\n","# 2023-10-16 11:42:00.508 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 11:42:00.509 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 204/275\n","# 2023-10-16 11:42:00.510 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.7418181818181818\n","\n","# 2023-10-16 11:42:00.518 | INFO     | __main__:results:157 - {'0': {'precision': 0.7609427609427609, 'recall': 0.8188405797101449, 'f1-score': 0.7888307155322862, 'support': 276}, '1': {'precision': 0.8031496062992126, 'recall': 0.7418181818181818, 'f1-score': 0.771266540642722, 'support': 275}, 'accuracy': 0.7803992740471869, 'macro avg': {'precision': 0.7820461836209868, 'recall': 0.7803293807641634, 'f1-score': 0.7800486280875041, 'support': 551}, 'weighted avg': {'precision': 0.7820078833983403, 'recall': 0.7803992740471869, 'f1-score': 0.7800645665402169, 'support': 551}}\n","# 2023-10-16 11:42:00.520 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.7609427609427609, 'recall': 0.8188405797101449, 'f1-score': 0.7888307155322862, 'support': 276}, '1': {'precision': 0.8031496062992126, 'recall': 0.7418181818181818, 'f1-score': 0.771266540642722, 'support': 275}, 'accuracy': 0.7803992740471869, 'macro avg': {'precision': 0.7820461836209868, 'recall': 0.7803293807641634, 'f1-score': 0.7800486280875041, 'support': 551}, 'weighted avg': {'precision': 0.7820078833983403, 'recall': 0.7803992740471869, 'f1-score': 0.7800645665402169, 'support': 551}}\n","# 2023-10-16 11:42:00.527 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 683 - DPT_2\n","# 2023-10-16 11:42:00.534 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 5234 - DPT_2\n","# 2023-10-16 11:42:00.536 | INFO     | __main__:<module>:8 - data_relevant_board: (683, 18) - DPT_2\n","# 2023-10-16 11:42:00.542 | INFO     | __main__:<module>:12 - data_irrelevant_board: (683, 18) - DPT_2\n","# 2023-10-16 11:42:00.545 | DEBUG    | __main__:<module>:18 - Department: DPT_2\n","# 2023-10-16 11:42:08.529 | DEBUG    | __main__:<module>:53 - Department count samples: label                   1366\n","# department              1366\n","# entry_date              1366\n","# general_id              1366\n","# normative_identifier    1366\n","# publication_date        1366\n","# regulatory_authority    1366\n","# subject                 1366\n","# subject_length          1366\n","# subject_unique_words    1366\n","# subject_words           1366\n","# content                 1366\n","# text_length             1366\n","# text_unique_words       1366\n","# text_words              1366\n","# type                    1366\n","# unique_document_id      1366\n","# url                     1366\n","# new_content             1366\n","# dtype: int64\n","# 2023-10-16 11:42:08.533 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   683\n","# department              683\n","# entry_date              683\n","# general_id              683\n","# normative_identifier    683\n","# publication_date        683\n","# regulatory_authority    683\n","# subject                 683\n","# subject_length          683\n","# subject_unique_words    683\n","# subject_words           683\n","# content                 683\n","# text_length             683\n","# text_unique_words       683\n","# text_words              683\n","# type                    683\n","# unique_document_id      683\n","# url                     683\n","# new_content             683\n","# dtype: int64\n","# 2023-10-16 11:42:08.536 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   683\n","# department              683\n","# entry_date              683\n","# general_id              683\n","# normative_identifier    683\n","# publication_date        683\n","# regulatory_authority    683\n","# subject                 683\n","# subject_length          683\n","# subject_unique_words    683\n","# subject_words           683\n","# content                 683\n","# text_length             683\n","# text_unique_words       683\n","# text_words              683\n","# type                    683\n","# unique_document_id      683\n","# url                     683\n","# new_content             683\n","# dtype: int64\n","# 2023-10-16 11:45:37.836 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 11:45:37.837 | INFO     | __main__:training_model:214 - Training loss: 0.6495405495166778\n","# 2023-10-16 11:45:53.980 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.533238364232553, [[-0.7536986  -0.3357893 ]\n","\n","# 2023-10-16 11:45:53.983 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.6972860125260961\n","# 2023-10-16 11:45:53.985 | INFO     | __main__:training_model:220 - Validation loss: 0.533238364232553\n","# 2023-10-16 11:45:53.986 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.6972860125260961\n","# 2023-10-16 11:47:17.688 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 11:47:17.690 | INFO     | __main__:training_model:214 - Training loss: 0.4142222485759042\n","# 2023-10-16 11:47:33.861 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.4689302623674676, [[-1.9490296   0.34441915]\n","\n","# 2023-10-16 11:47:33.865 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8083067092651757\n","# 2023-10-16 11:47:33.867 | INFO     | __main__:training_model:220 - Validation loss: 0.4689302623674676\n","# 2023-10-16 11:47:33.868 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8083067092651757\n","# 2023-10-16 11:48:54.737 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 11:48:54.738 | INFO     | __main__:training_model:214 - Training loss: 0.27152059091763064\n","# 2023-10-16 11:49:10.950 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.33486482098295883, [[-1.442017    0.17667153]\n","\n","# 2023-10-16 11:49:10.954 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8602941176470588\n","# 2023-10-16 11:49:10.956 | INFO     | __main__:training_model:220 - Validation loss: 0.33486482098295883\n","# 2023-10-16 11:49:10.957 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8602941176470588\n","# 2023-10-16 11:50:34.193 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 11:50:34.194 | INFO     | __main__:training_model:214 - Training loss: 0.16704543331129984\n","# 2023-10-16 11:50:50.389 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3773621565888862, [[ 0.12286378 -0.5268767 ]\n","\n","# 2023-10-16 11:50:50.393 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8671586715867159\n","# 2023-10-16 11:50:50.394 | INFO     | __main__:training_model:220 - Validation loss: 0.3773621565888862\n","# 2023-10-16 11:50:50.395 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8671586715867159\n","# 2023-10-16 11:52:11.354 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 11:52:11.356 | INFO     | __main__:training_model:214 - Training loss: 0.09682298820804466\n","# 2023-10-16 11:52:27.576 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3895244235172868, [[-1.0677322   0.00426753]\n","\n","# 2023-10-16 11:52:27.580 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8664259927797835\n","# 2023-10-16 11:52:27.581 | INFO     | __main__:training_model:220 - Validation loss: 0.3895244235172868\n","# 2023-10-16 11:52:27.582 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8664259927797835\n","# 2023-10-16 11:52:47.920 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3895244235172868, [[-1.0677322   0.00426753]\n","\n","# 2023-10-16 11:52:47.922 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 11:52:47.922 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 233/274\n","# 2023-10-16 11:52:47.923 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8503649635036497\n","\n","# 2023-10-16 11:52:47.924 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 11:52:47.925 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 240/273\n","# 2023-10-16 11:52:47.926 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8791208791208791\n","\n","# 2023-10-16 11:52:47.934 | INFO     | __main__:results:157 - {'0': {'precision': 0.8759398496240601, 'recall': 0.8503649635036497, 'f1-score': 0.8629629629629629, 'support': 274}, '1': {'precision': 0.8540925266903915, 'recall': 0.8791208791208791, 'f1-score': 0.8664259927797835, 'support': 273}, 'accuracy': 0.8647166361974405, 'macro avg': {'precision': 0.8650161881572258, 'recall': 0.8647429213122644, 'f1-score': 0.8646944778713732, 'support': 547}, 'weighted avg': {'precision': 0.8650361582878782, 'recall': 0.8647166361974405, 'f1-score': 0.8646913123962208, 'support': 547}}\n","# 2023-10-16 11:52:47.937 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.8759398496240601, 'recall': 0.8503649635036497, 'f1-score': 0.8629629629629629, 'support': 274}, '1': {'precision': 0.8540925266903915, 'recall': 0.8791208791208791, 'f1-score': 0.8664259927797835, 'support': 273}, 'accuracy': 0.8647166361974405, 'macro avg': {'precision': 0.8650161881572258, 'recall': 0.8647429213122644, 'f1-score': 0.8646944778713732, 'support': 547}, 'weighted avg': {'precision': 0.8650361582878782, 'recall': 0.8647166361974405, 'f1-score': 0.8646913123962208, 'support': 547}}\n","# 2023-10-16 11:52:47.945 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 600 - DPT_9\n","# 2023-10-16 11:52:47.951 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 3619 - DPT_9\n","# 2023-10-16 11:52:47.953 | INFO     | __main__:<module>:8 - data_relevant_board: (600, 18) - DPT_9\n","# 2023-10-16 11:52:47.959 | INFO     | __main__:<module>:12 - data_irrelevant_board: (600, 18) - DPT_9\n","# 2023-10-16 11:52:47.963 | DEBUG    | __main__:<module>:18 - Department: DPT_9\n","# 2023-10-16 11:52:50.370 | DEBUG    | __main__:<module>:53 - Department count samples: label                   1200\n","# department              1200\n","# entry_date              1200\n","# general_id              1200\n","# normative_identifier    1200\n","# publication_date        1200\n","# regulatory_authority    1200\n","# subject                 1200\n","# subject_length          1200\n","# subject_unique_words    1200\n","# subject_words           1200\n","# content                 1200\n","# text_length             1200\n","# text_unique_words       1200\n","# text_words              1200\n","# type                    1200\n","# unique_document_id      1200\n","# url                     1200\n","# new_content             1200\n","# dtype: int64\n","# 2023-10-16 11:52:50.374 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   600\n","# department              600\n","# entry_date              600\n","# general_id              600\n","# normative_identifier    600\n","# publication_date        600\n","# regulatory_authority    600\n","# subject                 600\n","# subject_length          600\n","# subject_unique_words    600\n","# subject_words           600\n","# content                 600\n","# text_length             600\n","# text_unique_words       600\n","# text_words              600\n","# type                    600\n","# unique_document_id      600\n","# url                     600\n","# new_content             600\n","# dtype: int64\n","# 2023-10-16 11:52:50.377 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   600\n","# department              600\n","# entry_date              600\n","# general_id              600\n","# normative_identifier    600\n","# publication_date        600\n","# regulatory_authority    600\n","# subject                 600\n","# subject_length          600\n","# subject_unique_words    600\n","# subject_words           600\n","# content                 600\n","# text_length             600\n","# text_unique_words       600\n","# text_words              600\n","# type                    600\n","# unique_document_id      600\n","# url                     600\n","# new_content             600\n","# dtype: int64\n","# 2023-10-16 11:54:45.611 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 11:54:45.612 | INFO     | __main__:training_model:214 - Training loss: 0.6898500298460325\n","# 2023-10-16 11:54:59.792 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.5837405091151595, [[ 0.14918342  0.27164683]\n"," \n","# 2023-10-16 11:54:59.796 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.7304347826086957\n","# 2023-10-16 11:54:59.797 | INFO     | __main__:training_model:220 - Validation loss: 0.5837405091151595\n","# 2023-10-16 11:54:59.798 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.7304347826086957\n","# 2023-10-16 11:56:11.503 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 11:56:11.504 | INFO     | __main__:training_model:214 - Training loss: 0.4294491931796074\n","# 2023-10-16 11:56:25.719 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.2984606445534155, [[-6.74726546e-01  5.34439087e-01]\n","\n","# 2023-10-16 11:56:25.722 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8698884758364313\n","# 2023-10-16 11:56:25.724 | INFO     | __main__:training_model:220 - Validation loss: 0.2984606445534155\n","# 2023-10-16 11:56:25.725 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8698884758364313\n","# 2023-10-16 11:57:39.641 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 11:57:39.643 | INFO     | __main__:training_model:214 - Training loss: 0.27194326914226014\n","# 2023-10-16 11:57:53.840 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.24180243522278033, [[-2.9578659e-01  2.8419337e-01]\n"," \n","# 2023-10-16 11:57:53.843 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8857715430861723\n","# 2023-10-16 11:57:53.844 | INFO     | __main__:training_model:220 - Validation loss: 0.24180243522278033\n","# 2023-10-16 11:57:53.845 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8857715430861723\n","# 2023-10-16 11:59:05.325 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 11:59:05.326 | INFO     | __main__:training_model:214 - Training loss: 0.20259228123662373\n","# 2023-10-16 11:59:19.535 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.25940157774311956, [[-0.6473328   0.654946  ]\n","\n","# 2023-10-16 11:59:19.539 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8951612903225807\n","# 2023-10-16 11:59:19.540 | INFO     | __main__:training_model:220 - Validation loss: 0.25940157774311956\n","# 2023-10-16 11:59:19.541 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8951612903225807\n","# 2023-10-16 12:00:33.555 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 12:00:33.557 | INFO     | __main__:training_model:214 - Training loss: 0.14043699767595777\n","# 2023-10-16 12:00:47.763 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.27973570268659387, [[-0.8096373   0.8088591 ]\n"," \n","# 2023-10-16 12:00:47.767 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8928571428571429\n","# 2023-10-16 12:00:47.768 | INFO     | __main__:training_model:220 - Validation loss: 0.27973570268659387\n","# 2023-10-16 12:00:47.769 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8928571428571429\n","# 2023-10-16 12:01:05.940 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.27973570268659387, [[-0.8096373   0.8088591 ]\n","\n","# 2023-10-16 12:01:05.942 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 12:01:05.942 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 201/240\n","# 2023-10-16 12:01:05.943 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8375\n","\n","# 2023-10-16 12:01:05.944 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 12:01:05.944 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 225/240\n","# 2023-10-16 12:01:05.945 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.9375\n","\n","# 2023-10-16 12:01:05.953 | INFO     | __main__:results:157 - {'0': {'precision': 0.9305555555555556, 'recall': 0.8375, 'f1-score': 0.881578947368421, 'support': 240}, '1': {'precision': 0.8522727272727273, 'recall': 0.9375, 'f1-score': 0.8928571428571429, 'support': 240}, 'accuracy': 0.8875, 'macro avg': {'precision': 0.8914141414141414, 'recall': 0.8875, 'f1-score': 0.887218045112782, 'support': 480}, 'weighted avg': {'precision': 0.8914141414141414, 'recall': 0.8875, 'f1-score': 0.887218045112782, 'support': 480}}\n","# 2023-10-16 12:01:05.955 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.9305555555555556, 'recall': 0.8375, 'f1-score': 0.881578947368421, 'support': 240}, '1': {'precision': 0.8522727272727273, 'recall': 0.9375, 'f1-score': 0.8928571428571429, 'support': 240}, 'accuracy': 0.8875, 'macro avg': {'precision': 0.8914141414141414, 'recall': 0.8875, 'f1-score': 0.887218045112782, 'support': 480}, 'weighted avg': {'precision': 0.8914141414141414, 'recall': 0.8875, 'f1-score': 0.887218045112782, 'support': 480}}\n","# 2023-10-16 12:01:05.962 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 534 - DPT_5\n","# 2023-10-16 12:01:05.967 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 2594 - DPT_5\n","# 2023-10-16 12:01:05.969 | INFO     | __main__:<module>:8 - data_relevant_board: (534, 18) - DPT_5\n","# 2023-10-16 12:01:05.975 | INFO     | __main__:<module>:12 - data_irrelevant_board: (534, 18) - DPT_5\n","# 2023-10-16 12:01:05.978 | DEBUG    | __main__:<module>:18 - Department: DPT_5\n","# 2023-10-16 12:01:09.668 | DEBUG    | __main__:<module>:53 - Department count samples: label                   1068\n","# department              1068\n","# entry_date              1068\n","# general_id              1068\n","# normative_identifier    1068\n","# publication_date        1068\n","# regulatory_authority    1068\n","# subject                 1068\n","# subject_length          1068\n","# subject_unique_words    1068\n","# subject_words           1068\n","# content                 1068\n","# text_length             1068\n","# text_unique_words       1068\n","# text_words              1068\n","# type                    1068\n","# unique_document_id      1068\n","# url                     1068\n","# new_content             1068\n","# dtype: int64\n","# 2023-10-16 12:01:09.672 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   534\n","# department              534\n","# entry_date              534\n","# general_id              534\n","# normative_identifier    534\n","# publication_date        534\n","# regulatory_authority    534\n","# subject                 534\n","# subject_length          534\n","# subject_unique_words    534\n","# subject_words           534\n","# content                 534\n","# text_length             534\n","# text_unique_words       534\n","# text_words              534\n","# type                    534\n","# unique_document_id      534\n","# url                     534\n","# new_content             534\n","# dtype: int64\n","# 2023-10-16 12:01:09.675 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   534\n","# department              534\n","# entry_date              534\n","# general_id              534\n","# normative_identifier    534\n","# publication_date        534\n","# regulatory_authority    534\n","# subject                 534\n","# subject_length          534\n","# subject_unique_words    534\n","# subject_words           534\n","# content                 534\n","# text_length             534\n","# text_unique_words       534\n","# text_words              534\n","# type                    534\n","# unique_document_id      534\n","# url                     534\n","# new_content             534\n","# dtype: int64\n","# 2023-10-16 12:03:16.098 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 12:03:16.100 | INFO     | __main__:training_model:214 - Training loss: 0.6934657166170519\n","# 2023-10-16 12:03:28.773 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.5880766634283394, [[ 5.12984097e-01  2.11001709e-01]\n","\n","# 2023-10-16 12:03:28.776 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.7208791208791209\n","# 2023-10-16 12:03:28.777 | INFO     | __main__:training_model:220 - Validation loss: 0.5880766634283394\n","# 2023-10-16 12:03:28.779 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.7208791208791209\n","# 2023-10-16 12:04:35.540 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 12:04:35.541 | INFO     | __main__:training_model:214 - Training loss: 0.5372880641804185\n","# 2023-10-16 12:04:48.214 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.4916709389152198, [[-5.33580482e-01  1.74760044e-01]\n","\n","# 2023-10-16 12:04:48.218 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.7975951903807615\n","# 2023-10-16 12:04:48.219 | INFO     | __main__:training_model:220 - Validation loss: 0.4916709389152198\n","# 2023-10-16 12:04:48.220 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.7975951903807615\n","# 2023-10-16 12:05:52.577 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 12:05:52.578 | INFO     | __main__:training_model:214 - Training loss: 0.35578080561271935\n","# 2023-10-16 12:06:05.273 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.3540103050141499, [[-0.45018533  0.15728012]\n","\n","# 2023-10-16 12:06:05.277 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8137931034482758\n","# 2023-10-16 12:06:05.279 | INFO     | __main__:training_model:220 - Validation loss: 0.3540103050141499\n","# 2023-10-16 12:06:05.280 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8137931034482758\n","# 2023-10-16 12:07:12.149 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 12:07:12.150 | INFO     | __main__:training_model:214 - Training loss: 0.22603321690545525\n","# 2023-10-16 12:07:24.831 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.37821456748221455, [[-1.14101827e+00  2.98565328e-01]\n","\n","# 2023-10-16 12:07:24.834 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8347826086956522\n","# 2023-10-16 12:07:24.835 | INFO     | __main__:training_model:220 - Validation loss: 0.37821456748221455\n","# 2023-10-16 12:07:24.836 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8347826086956522\n","# 2023-10-16 12:08:31.827 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 12:08:31.829 | INFO     | __main__:training_model:214 - Training loss: 0.1468432017190512\n","# 2023-10-16 12:08:44.491 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.43002483425340776, [[-1.6764097   0.6225817 ]\n","\n","# 2023-10-16 12:08:44.495 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8275862068965518\n","# 2023-10-16 12:08:44.496 | INFO     | __main__:training_model:220 - Validation loss: 0.43002483425340776\n","# 2023-10-16 12:08:44.498 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8275862068965518\n","# 2023-10-16 12:09:01.316 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.43002483425340776, [[-1.6764097   0.6225817 ]\n","\n","# 2023-10-16 12:09:01.318 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 12:09:01.319 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 156/214\n","# 2023-10-16 12:09:01.320 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.7289719626168224\n","\n","# 2023-10-16 12:09:01.321 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 12:09:01.322 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 192/214\n","# 2023-10-16 12:09:01.323 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.897196261682243\n","\n","# 2023-10-16 12:09:01.331 | INFO     | __main__:results:157 - {'0': {'precision': 0.8764044943820225, 'recall': 0.7289719626168224, 'f1-score': 0.7959183673469389, 'support': 214}, '1': {'precision': 0.768, 'recall': 0.897196261682243, 'f1-score': 0.8275862068965518, 'support': 214}, 'accuracy': 0.8130841121495327, 'macro avg': {'precision': 0.8222022471910113, 'recall': 0.8130841121495327, 'f1-score': 0.8117522871217453, 'support': 428}, 'weighted avg': {'precision': 0.8222022471910112, 'recall': 0.8130841121495327, 'f1-score': 0.8117522871217454, 'support': 428}}\n","# 2023-10-16 12:09:01.333 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.8764044943820225, 'recall': 0.7289719626168224, 'f1-score': 0.7959183673469389, 'support': 214}, '1': {'precision': 0.768, 'recall': 0.897196261682243, 'f1-score': 0.8275862068965518, 'support': 214}, 'accuracy': 0.8130841121495327, 'macro avg': {'precision': 0.8222022471910113, 'recall': 0.8130841121495327, 'f1-score': 0.8117522871217453, 'support': 428}, 'weighted avg': {'precision': 0.8222022471910112, 'recall': 0.8130841121495327, 'f1-score': 0.8117522871217454, 'support': 428}}\n","# 2023-10-16 12:09:01.341 | INFO     | __main__:<module>:4 - total_relevant_documents_of_the_board: 439 - DPT_16\n","# 2023-10-16 12:09:01.346 | INFO     | __main__:<module>:5 - Total irrelevant documents of the department: 1558 - DPT_16\n","# 2023-10-16 12:09:01.348 | INFO     | __main__:<module>:8 - data_relevant_board: (439, 18) - DPT_16\n","# 2023-10-16 12:09:01.354 | INFO     | __main__:<module>:12 - data_irrelevant_board: (439, 18) - DPT_16\n","# 2023-10-16 12:09:01.358 | DEBUG    | __main__:<module>:18 - Department: DPT_16\n","# 2023-10-16 12:09:06.785 | DEBUG    | __main__:<module>:53 - Department count samples: label                   878\n","# department              878\n","# entry_date              878\n","# general_id              878\n","# normative_identifier    878\n","# publication_date        878\n","# regulatory_authority    878\n","# subject                 878\n","# subject_length          878\n","# subject_unique_words    878\n","# subject_words           878\n","# content                 878\n","# text_length             878\n","# text_unique_words       878\n","# text_words              878\n","# type                    878\n","# unique_document_id      878\n","# url                     878\n","# new_content             878\n","# dtype: int64\n","# 2023-10-16 12:09:06.789 | DEBUG    | __main__:<module>:54 - Department count samples class 1: label                   439\n","# department              439\n","# entry_date              439\n","# general_id              439\n","# normative_identifier    439\n","# publication_date        439\n","# regulatory_authority    439\n","# subject                 439\n","# subject_length          439\n","# subject_unique_words    439\n","# subject_words           439\n","# content                 439\n","# text_length             439\n","# text_unique_words       439\n","# text_words              439\n","# type                    439\n","# unique_document_id      439\n","# url                     439\n","# new_content             439\n","# dtype: int64\n","# 2023-10-16 12:09:06.793 | DEBUG    | __main__:<module>:55 - Department count samples class 0: label                   439\n","# department              439\n","# entry_date              439\n","# general_id              439\n","# normative_identifier    439\n","# publication_date        439\n","# regulatory_authority    439\n","# subject                 439\n","# subject_length          439\n","# subject_unique_words    439\n","# subject_words           439\n","# content                 439\n","# text_length             439\n","# text_unique_words       439\n","# text_words              439\n","# type                    439\n","# unique_document_id      439\n","# url                     439\n","# new_content             439\n","# dtype: int64\n","# 2023-10-16 12:11:30.450 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-16 12:11:30.453 | INFO     | __main__:training_model:214 - Training loss: 0.6689137096206347\n","# 2023-10-16 12:11:40.846 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.5383422747254372, [[-0.61664087 -0.26155   ]\n","\n","# 2023-10-16 12:11:40.850 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8020050125313283\n","# 2023-10-16 12:11:40.851 | INFO     | __main__:training_model:220 - Validation loss: 0.5383422747254372\n","# 2023-10-16 12:11:40.852 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8020050125313283\n","# 2023-10-16 12:12:37.051 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-16 12:12:37.052 | INFO     | __main__:training_model:214 - Training loss: 0.5244079108039538\n","# 2023-10-16 12:12:47.453 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.4673820994794369, [[-0.771734   -0.33849487]\n","\n","# 2023-10-16 12:12:47.456 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.6199261992619927\n","# 2023-10-16 12:12:47.458 | INFO     | __main__:training_model:220 - Validation loss: 0.4673820994794369\n","# 2023-10-16 12:12:47.459 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.6199261992619927\n","# 2023-10-16 12:13:41.471 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-16 12:13:41.472 | INFO     | __main__:training_model:214 - Training loss: 0.418528500944376\n","# 2023-10-16 12:13:51.900 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.32494894104699296, [[-0.13720173 -0.28249618]\n","\n","# 2023-10-16 12:13:51.905 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8522727272727273\n","# 2023-10-16 12:13:51.906 | INFO     | __main__:training_model:220 - Validation loss: 0.32494894104699296\n","# 2023-10-16 12:13:51.907 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8522727272727273\n","# 2023-10-16 12:14:48.008 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-16 12:14:48.009 | INFO     | __main__:training_model:214 - Training loss: 0.32487695167462033\n","# 2023-10-16 12:14:58.419 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.32893385652763146, [[ 0.3284121  -0.29890972]\n","\n","# 2023-10-16 12:14:58.423 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8650137741046832\n","# 2023-10-16 12:14:58.424 | INFO     | __main__:training_model:220 - Validation loss: 0.32893385652763146\n","# 2023-10-16 12:14:58.425 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8650137741046832\n","# 2023-10-16 12:15:55.090 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-16 12:15:55.092 | INFO     | __main__:training_model:214 - Training loss: 0.2721165236499574\n","# 2023-10-16 12:16:05.496 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.2886545436146359, [[-0.840442   -0.1579147 ]\n","\n","# 2023-10-16 12:16:05.500 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.8804347826086957\n","# 2023-10-16 12:16:05.501 | INFO     | __main__:training_model:220 - Validation loss: 0.2886545436146359\n","# 2023-10-16 12:16:05.502 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.8804347826086957\n","# 2023-10-16 12:16:19.847 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.2886545436146359, [[-0.840442   -0.1579147 ]\n","\n","# 2023-10-16 12:16:19.849 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-16 12:16:19.850 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 146/176\n","# 2023-10-16 12:16:19.851 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.8295454545454546\n","\n","# 2023-10-16 12:16:19.852 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-16 12:16:19.853 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 162/176\n","# 2023-10-16 12:16:19.853 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.9204545454545454\n","\n","# 2023-10-16 12:16:19.861 | INFO     | __main__:results:157 - {'0': {'precision': 0.9125, 'recall': 0.8295454545454546, 'f1-score': 0.869047619047619, 'support': 176}, '1': {'precision': 0.84375, 'recall': 0.9204545454545454, 'f1-score': 0.8804347826086957, 'support': 176}, 'accuracy': 0.875, 'macro avg': {'precision': 0.878125, 'recall': 0.875, 'f1-score': 0.8747412008281573, 'support': 352}, 'weighted avg': {'precision': 0.878125, 'recall': 0.875, 'f1-score': 0.8747412008281572, 'support': 352}}\n","# 2023-10-16 12:16:19.863 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.9125, 'recall': 0.8295454545454546, 'f1-score': 0.869047619047619, 'support': 176}, '1': {'precision': 0.84375, 'recall': 0.9204545454545454, 'f1-score': 0.8804347826086957, 'support': 176}, 'accuracy': 0.875, 'macro avg': {'precision': 0.878125, 'recall': 0.875, 'f1-score': 0.8747412008281573, 'support': 352}, 'weighted avg': {'precision': 0.878125, 'recall': 0.875, 'f1-score': 0.8747412008281572, 'support': 352}}\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
