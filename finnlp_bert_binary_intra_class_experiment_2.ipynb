{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_validate\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from loguru import logger as lg\n","import multiprocessing\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.svm import SVC\n","\n","import transformers\n","import torch\n","import random\n","\n","import random\n","import string\n","import numpy as np\n","import unidecode\n","from unidecode import unidecode\n","from wordcloud import STOPWORDS\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n","from torch.utils.data import TensorDataset\n","from tqdm.notebook import tqdm\n","from transformers import AutoModel, AutoTokenizer, BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, PreTrainedTokenizerFast\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn import metrics\n","import tensorflow as tf\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import torch\n","transformers.logging.set_verbosity_debug()\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-01 18:28:53.268 | INFO     | __main__:<module>:6 - \n","\n","####################################### NEW EXECUTION #######################################\n","\n","\n","2024-03-01 18:28:53.271 | INFO     | __main__:<module>:7 - Processors (cores) available: 38\n"]}],"source":["NUM_PROCESSORS = (multiprocessing.cpu_count() - 2)\n","VERBOSE = 0\n","DEPARTMENTS_QUANTITY_TO_TRAIN = 6\n","lg.add(\"logging/finnlp_bert_binary_intra_class_experiment_2.log\", rotation=\"1024 MB\")\n","lg.info(\"\\n\\n####################################### NEW EXECUTION #######################################\\n\\n\")\n","lg.info(f\"Processors (cores) available: {NUM_PROCESSORS}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["brc = pd.read_csv(\"Banking_Regulation_Corpora_BRC_anonymous.csv\" ,encoding=\"utf-8\", low_memory=False, sep=\";\")\n","data_relevant = brc[brc['class'] == 1]\n","data_irrelevant = brc[brc['class'] == 0]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["BATCH_SIZE = 31"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Evaluate which regulators get in each department to make the intra-class balancing strategy</h3>"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["lt = ['DPT_25', 'DPT_3', 'DPT_2', 'DPT_9', 'DPT_5', 'DPT_16']"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DPT_25  -  [('BACEN', 666), ('PRESIDÊNCIA_DA_REPÚBLICA', 29), ('COAF', 28), ('DOU', 26), ('ANAC', 14), ('RFB', 14)]\n","DPT_3  -  [('B3', 302), ('BACEN', 175), ('CETIP', 99), ('ANBIMA', 55), ('CVM', 49), ('RFB', 7)]\n","DPT_2  -  [('CVM', 253), ('ANBIMA', 221), ('B3', 147), ('COAF', 18), ('BACEN', 16), ('RFB', 13)]\n","DPT_9  -  [('BACEN', 205), ('CIP', 198), ('DOU', 64), ('BNDES', 55), ('PRESIDÊNCIA_DA_REPÚBLICA', 32), ('NUCLEA', 17)]\n","DPT_5  -  [('BACEN', 193), ('CVM', 126), ('DOU', 107), ('RFB', 79), ('CFC', 22), ('CPC', 13)]\n","DPT_16  -  [('B3', 97), ('CETIP', 85), ('BACEN', 68), ('STN', 67), ('RFB', 24), ('ANBIMA', 20)]\n"]}],"source":["for l in lt:\n","    dfr = data_relevant[data_relevant.department.isin([l])]\n","    dddd = dict(dfr.regulatory_authority.value_counts())\n","    print(l,' - ',list(dict(sorted(dddd.items(), key=lambda item: item[1], reverse=True)).items())[:6])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# We chose the regulators with more documents in the relevant class of each of the three departments.\n","# The regulators must exist in both classes of the department.\n","# Only regulators with more than 10 documents in the relevant class where chosen.\n","# To make the undersampling, we took the regulator with less documents in the relevant class for each department, 26 documents at DPT_25, for example.\n","\n","# DPT_25  -  [('BACEN', 666), ('PRESIDÊNCIA_DA_REPÚBLICA', 29), ('COAF', 28), ('DOU', 26)] # relevant\n","# DPT_25  -  [('DOU', 2982), ('BACEN', 467), ('COAF', 48), ('PRESIDÊNCIA_DA_REPÚBLICA', 32)] # irrelevant\n","\n","# DPT_3  -  [('B3', 302), ('BACEN', 175), ('ANBIMA', 55), ('CVM', 49)] # relevant\n","# DPT_3  -  [('B3', 592), ('CVM', 368), ('BACEN', 257), ('ANBIMA', 85)] # irrelevant\n","\n","# DPT_2  -  [('CVM', 253), ('ANBIMA', 221), ('B3', 147), ('RFB', 13)] # relevant\n","# DPT_2  -  [('B3', 1921), ('CVM', 783), ('RFB', 678), ('ANBIMA', 399)] # irrelevant"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DPT_25  -  [('DOU', 2982), ('BACEN', 467), ('ANAC', 421), ('COAF', 48), ('PRESIDÊNCIA_DA_REPÚBLICA', 32), ('NUCLEA', 26)]\n","DPT_3  -  [('B3', 592), ('CVM', 368), ('STN', 264), ('BACEN', 257), ('RFB', 161), ('ANBIMA', 85)]\n","DPT_2  -  [('B3', 1921), ('CVM', 783), ('CAMARA_MUNICIPAL_DO_RIO_DE_JANEIRO', 744), ('RFB', 678), ('ANBIMA', 399), ('SUSEP', 391)]\n","DPT_9  -  [('BACEN', 826), ('CIP', 712), ('CVM', 531), ('RFB', 331), ('STN', 269), ('DOU', 230)]\n","DPT_5  -  [('DOU', 1147), ('BACEN', 658), ('RFB', 327), ('PRESIDÊNCIA_DA_REPÚBLICA', 201), ('CVM', 158), ('NUCLEA', 60)]\n","DPT_16  -  [('BACEN', 337), ('STN', 294), ('RFB', 270), ('CVM', 162), ('B3', 121), ('CAMARA_MUNICIPAL_DO_RIO_DE_JANEIRO', 101)]\n"]}],"source":["for l in lt:\n","    dfi = data_irrelevant[data_irrelevant.department.isin([l])]\n","    dddd = dict(dfi.regulatory_authority.value_counts())\n","    print(l,' - ',list(dict(sorted(dddd.items(), key=lambda item: item[1], reverse=True)).items())[:6])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>department</th>\n","      <th>entry_date</th>\n","      <th>general_id</th>\n","      <th>normative_identifier</th>\n","      <th>publication_date</th>\n","      <th>regulatory_authority</th>\n","      <th>subject</th>\n","      <th>subject_length</th>\n","      <th>subject_unique_words</th>\n","      <th>subject_words</th>\n","      <th>text</th>\n","      <th>text_length</th>\n","      <th>text_unique_words</th>\n","      <th>text_words</th>\n","      <th>type</th>\n","      <th>unique_document_id</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [class, department, entry_date, general_id, normative_identifier, publication_date, regulatory_authority, subject, subject_length, subject_unique_words, subject_words, text, text_length, text_unique_words, text_words, type, unique_document_id, url]\n","Index: []"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["aux_relevant = []\n","\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25 = 26\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3 = 49\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2 = 13\n","\n","# DPT_25\n","dpt_25 = data_relevant[data_relevant.department.isin(['DPT_25'])]\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['BACEN'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['PRESIDÊNCIA_DA_REPÚBLICA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['COAF'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['DOU'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_relevant.append(regulator)\n","# DPT_25\n","\n","# DPT_3\n","dpt_3 = data_relevant[data_relevant.department.isin(['DPT_3'])]\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['B3'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['BACEN'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['ANBIMA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['CVM'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_relevant.append(regulator)\n","# DPT_3\n","\n","# DPT_2\n","dpt_2 = data_relevant[data_relevant.department.isin(['DPT_2'])]\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['CVM'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['ANBIMA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['B3'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_relevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['RFB'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_relevant.append(regulator)\n","# DPT_2\n","\n","data_relevant = pd.concat(aux_relevant)\n","\n","data_relevant[data_relevant.text_words < 50]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["(352, 18)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant.shape"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["352"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["(13*4)+(49*4)+(26*4)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>department</th>\n","      <th>entry_date</th>\n","      <th>general_id</th>\n","      <th>normative_identifier</th>\n","      <th>publication_date</th>\n","      <th>regulatory_authority</th>\n","      <th>subject</th>\n","      <th>subject_length</th>\n","      <th>subject_unique_words</th>\n","      <th>subject_words</th>\n","      <th>text</th>\n","      <th>text_length</th>\n","      <th>text_unique_words</th>\n","      <th>text_words</th>\n","      <th>type</th>\n","      <th>unique_document_id</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [class, department, entry_date, general_id, normative_identifier, publication_date, regulatory_authority, subject, subject_length, subject_unique_words, subject_words, text, text_length, text_unique_words, text_words, type, unique_document_id, url]\n","Index: []"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["aux_irrelevant = []\n","\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25 = 26\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3 = 49\n","SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2 = 13\n","\n","# DPT_25\n","dpt_25 = data_irrelevant[data_irrelevant.department.isin(['DPT_25'])]\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['BACEN'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['PRESIDÊNCIA_DA_REPÚBLICA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['COAF'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_25[dpt_25.regulatory_authority.isin(['DOU'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_25]\n","aux_irrelevant.append(regulator)\n","# DPT_25\n","\n","# DPT_3\n","dpt_3 = data_irrelevant[data_irrelevant.department.isin(['DPT_3'])]\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['B3'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['BACEN'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['ANBIMA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_3[dpt_3.regulatory_authority.isin(['CVM'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_3]\n","aux_irrelevant.append(regulator)\n","# DPT_3\n","\n","# DPT_2\n","dpt_2 = data_irrelevant[data_irrelevant.department.isin(['DPT_2'])]\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['CVM'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['ANBIMA'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['B3'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_irrelevant.append(regulator)\n","\n","regulator = dpt_2[dpt_2.regulatory_authority.isin(['RFB'])]\n","regulator = regulator[regulator.text_words >= 50][:SMALLEST_QUANTITY_RELEVANT_SAMPLES_DPT_2]\n","aux_irrelevant.append(regulator)\n","# DPT_2\n","\n","data_irrelevant = pd.concat(aux_irrelevant)\n","\n","data_irrelevant[data_irrelevant.text_words < 50]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(352, 18)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant.shape"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>department</th>\n","      <th>entry_date</th>\n","      <th>general_id</th>\n","      <th>normative_identifier</th>\n","      <th>publication_date</th>\n","      <th>regulatory_authority</th>\n","      <th>subject</th>\n","      <th>subject_length</th>\n","      <th>subject_unique_words</th>\n","      <th>subject_words</th>\n","      <th>text</th>\n","      <th>text_length</th>\n","      <th>text_unique_words</th>\n","      <th>text_words</th>\n","      <th>type</th>\n","      <th>unique_document_id</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7846</th>\n","      <td>0</td>\n","      <td>DPT_25</td>\n","      <td>2020-08-31</td>\n","      <td>2169</td>\n","      <td>0301/2020</td>\n","      <td>2020-08-31</td>\n","      <td>BACEN</td>\n","      <td>Caracterizado fornecimento intempestivo ao Ba...</td>\n","      <td>294</td>\n","      <td>36.0</td>\n","      <td>49.0</td>\n","      <td>​DEPARTAMENTO DE RESOLUÇÃO E DE AÇÃO SANCIONAD...</td>\n","      <td>758</td>\n","      <td>81.0</td>\n","      <td>113.0</td>\n","      <td>PROCESSO ADMINISTRATIVO SANCIONADOR</td>\n","      <td>729080</td>\n","      <td>https://www.bcb.gov.br/estabilidadefinanceira/...</td>\n","    </tr>\n","    <tr>\n","      <th>7847</th>\n","      <td>0</td>\n","      <td>DPT_25</td>\n","      <td>2020-08-31</td>\n","      <td>2170</td>\n","      <td>36121</td>\n","      <td>2020-08-31</td>\n","      <td>BACEN</td>\n","      <td>Divulga nome aprovado de pessoas eleitas/nomea...</td>\n","      <td>167</td>\n","      <td>21.0</td>\n","      <td>23.0</td>\n","      <td>Divulgamos o nome aprovado de pessoas eleitas/...</td>\n","      <td>7080</td>\n","      <td>407.0</td>\n","      <td>966.0</td>\n","      <td>COMUNICADO</td>\n","      <td>729131</td>\n","      <td>https://www.bcb.gov.br/estabilidadefinanceira/...</td>\n","    </tr>\n","    <tr>\n","      <th>7848</th>\n","      <td>0</td>\n","      <td>DPT_25</td>\n","      <td>2020-08-31</td>\n","      <td>2171</td>\n","      <td>36123</td>\n","      <td>2020-08-31</td>\n","      <td>BACEN</td>\n","      <td>Divulga nome de pessoas com intenção de ocupar...</td>\n","      <td>140</td>\n","      <td>19.0</td>\n","      <td>21.0</td>\n","      <td>Divulgamos os nomes de pretendentes a cargos d...</td>\n","      <td>1558</td>\n","      <td>149.0</td>\n","      <td>276.0</td>\n","      <td>COMUNICADO</td>\n","      <td>729151</td>\n","      <td>https://www.bcb.gov.br/estabilidadefinanceira/...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      class department  entry_date  general_id normative_identifier  \\\n","7846      0     DPT_25  2020-08-31        2169            0301/2020   \n","7847      0     DPT_25  2020-08-31        2170                36121   \n","7848      0     DPT_25  2020-08-31        2171                36123   \n","\n","     publication_date regulatory_authority  \\\n","7846       2020-08-31                BACEN   \n","7847       2020-08-31                BACEN   \n","7848       2020-08-31                BACEN   \n","\n","                                                subject  subject_length  \\\n","7846   Caracterizado fornecimento intempestivo ao Ba...             294   \n","7847  Divulga nome aprovado de pessoas eleitas/nomea...             167   \n","7848  Divulga nome de pessoas com intenção de ocupar...             140   \n","\n","      subject_unique_words  subject_words  \\\n","7846                  36.0           49.0   \n","7847                  21.0           23.0   \n","7848                  19.0           21.0   \n","\n","                                                   text  text_length  \\\n","7846  ​DEPARTAMENTO DE RESOLUÇÃO E DE AÇÃO SANCIONAD...          758   \n","7847  Divulgamos o nome aprovado de pessoas eleitas/...         7080   \n","7848  Divulgamos os nomes de pretendentes a cargos d...         1558   \n","\n","      text_unique_words  text_words                                 type  \\\n","7846               81.0       113.0  PROCESSO ADMINISTRATIVO SANCIONADOR   \n","7847              407.0       966.0                           COMUNICADO   \n","7848              149.0       276.0                           COMUNICADO   \n","\n","      unique_document_id                                                url  \n","7846              729080  https://www.bcb.gov.br/estabilidadefinanceira/...  \n","7847              729131  https://www.bcb.gov.br/estabilidadefinanceira/...  \n","7848              729151  https://www.bcb.gov.br/estabilidadefinanceira/...  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant.head(3)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["class                   352\n","department              352\n","entry_date              352\n","general_id              352\n","normative_identifier    352\n","publication_date        352\n","regulatory_authority    352\n","subject                 352\n","subject_length          352\n","subject_unique_words    352\n","subject_words           352\n","text                    352\n","text_length             352\n","text_unique_words       352\n","text_words              352\n","type                    352\n","unique_document_id      352\n","url                     352\n","dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant.count()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["class                   352\n","department              352\n","entry_date              352\n","general_id              352\n","normative_identifier    352\n","publication_date        352\n","regulatory_authority    352\n","subject                 352\n","subject_length          352\n","subject_unique_words    352\n","subject_words           352\n","text                    352\n","text_length             352\n","text_unique_words       352\n","text_words              352\n","type                    352\n","unique_document_id      352\n","url                     352\n","dtype: int64"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant = data_relevant[data_relevant.text_words >= 50]\n","data_relevant.count()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["class                   352\n","department              352\n","entry_date              352\n","general_id              352\n","normative_identifier    352\n","publication_date        352\n","regulatory_authority    352\n","subject                 352\n","subject_length          352\n","subject_unique_words    352\n","subject_words           352\n","text                    352\n","text_length             352\n","text_unique_words       352\n","text_words              352\n","type                    352\n","unique_document_id      352\n","url                     352\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant.count()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["class                   352\n","department              352\n","entry_date              352\n","general_id              352\n","normative_identifier    352\n","publication_date        352\n","regulatory_authority    352\n","subject                 352\n","subject_length          352\n","subject_unique_words    352\n","subject_words           352\n","text                    352\n","text_length             352\n","text_unique_words       352\n","text_words              352\n","type                    352\n","unique_document_id      352\n","url                     352\n","dtype: int64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["data_irrelevant = data_irrelevant[data_irrelevant.text_words >= 50]\n","data_irrelevant.count()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["array(['DPT_25', 'DPT_3', 'DPT_2'], dtype=object)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["data_relevant['department'].unique()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["3"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["len(list(data_relevant['department'].unique()))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["class Model_BERT():\n","    \n","    def model_path_def(self, name_model):\n","        if name_model == \"BERTIMBAU_BASE\":\n","            model_path = MODEL_PATH\n","        elif name_model == \"XXXX\":\n","            model_path = MODEL_PATH_NEW\n","        else:\n","            print(\"Nome de modelo inválido\")\n","            model_path = \"None\"\n","            \n","        return model_path\n","\n","    def tokenizer_model(self, model_path, df, token):\n","        tokenizer = BertTokenizer.from_pretrained(BERTIMBAU_TOKENIZER, do_lower_case=True)\n","\n","        # Tokenizing the training data\n","        encoded_data_train = tokenizer.batch_encode_plus(\n","            df[df.data_type=='train'].new_content.tolist(), \n","            add_special_tokens=True, \n","            return_attention_mask=True, \n","            padding=True, \n","            max_length=token, \n","            return_tensors='pt',\n","            truncation=True\n","        )\n","\n","        # Tokenizing test data\n","        encoded_data_val = tokenizer.batch_encode_plus(\n","            df[df.data_type=='val'].new_content.tolist(), \n","            add_special_tokens=True, \n","            return_attention_mask=True, \n","            padding=True,\n","            max_length=token, \n","            return_tensors='pt',\n","            truncation=True\n","        )\n","\n","\n","        input_ids_train = encoded_data_train['input_ids']\n","        attention_masks_train = encoded_data_train['attention_mask']\n","        labels_train = torch.tensor(df[df.data_type=='train'].label_num.values)\n","\n","        input_ids_val = encoded_data_val['input_ids']\n","        attention_masks_val = encoded_data_val['attention_mask']\n","        labels_val = torch.tensor(df[df.data_type=='val'].label_num.values)\n","\n","        dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","        dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n","        \n","        return(dataset_train, dataset_val)\n","\n","    def setup_model(self, model_path, dataset_train, dataset_val, epochs):\n","        model = BertForSequenceClassification.from_pretrained(model_path,\n","                                                              num_labels=len(LABEL_DICT),\n","                                                              output_attentions=False,\n","                                                              output_hidden_states=False)\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model.to(device)\n","        batch_size = BATCH_SIZE\n","        dataloader_train = DataLoader(dataset_train, \n","                                      sampler=RandomSampler(dataset_train), \n","                                      batch_size=batch_size)\n","        dataloader_validation = DataLoader(dataset_val, \n","                                           sampler=SequentialSampler(dataset_val), \n","                                           batch_size=batch_size)\n","        optimizer = AdamW(model.parameters(),\n","                          lr=1e-5, \n","                          eps=1e-8)\n","\n","        scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                    num_warmup_steps=100,\n","                                                    num_training_steps=len(dataloader_train)*epochs)\n","        return(model, dataloader_train, dataloader_validation, epochs, scheduler, optimizer, device)\n","\n","\n","    def f1_score_func(self, preds, labels):\n","        preds_flat = np.argmax(preds, axis=1).flatten()\n","        labels_flat = labels.flatten()\n","\n","        scr = f1_score(labels_flat, preds_flat, average='binary')\n","        lg.info(f\"f1_score_binary: {scr}\")\n","        return scr\n","\n","    def accuracy_per_class(self, preds, labels):\n","        label_dict_inverse = {v: k for k, v in LABEL_DICT.items()}\n","\n","        preds_flat = np.argmax(preds, axis=1).flatten()\n","        labels_flat = labels.flatten()\n","\n","        for label in np.unique(labels_flat):\n","            y_preds = preds_flat[labels_flat==label]\n","            y_true = labels_flat[labels_flat==label]\n","            print(f'Class: {label_dict_inverse[label]}')\n","            print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}')\n","            print(f'% Accuracy: {len(y_preds[y_preds==label])/len(y_true)}\\n')\n","            lg.info(f'Class: {label_dict_inverse[label]}')\n","            lg.info(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}')\n","            lg.info(f'% Accuracy: {len(y_preds[y_preds==label])/len(y_true)}\\n')\n","        \n","    def evaluate(self, model, dataloader_val, device):\n","\n","        model.eval()\n","\n","        loss_val_total = 0\n","        predictions, true_vals = [], []\n","\n","        for batch in dataloader_val:\n","\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            with torch.no_grad():        \n","                outputs = model(**inputs)\n","\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            loss_val_total += loss.item()\n","\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = inputs['labels'].cpu().numpy()\n","            predictions.append(logits)\n","            true_vals.append(label_ids)\n","\n","        loss_val_avg = loss_val_total/len(dataloader_val) \n","\n","        predictions = np.concatenate(predictions, axis=0)\n","        true_vals = np.concatenate(true_vals, axis=0)\n","\n","        lg.info(f\"loss_val_avg, predictions, true_vals: {loss_val_avg}, {predictions}, {true_vals}\")\n","\n","        return loss_val_avg, predictions, true_vals\n","\n","    def results(self, model_path, model_name, epochs, dataloader_validation, device, token):\n","        model = BertForSequenceClassification.from_pretrained(model_path,\n","                                                              num_labels=len(LABEL_DICT),\n","                                                              output_attentions=False,\n","                                                              output_hidden_states=False)\n","\n","        model.to(device)\n","\n","        model.load_state_dict(torch.load(f'{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epochs}.model', map_location=torch.device('cpu')))\n","\n","        _, predictions, true_vals = Model_BERT().evaluate(model, dataloader_validation, device)\n","        Model_BERT().accuracy_per_class(predictions, true_vals)\n","        from sklearn import metrics\n","        preds_flat = np.argmax(predictions, axis=1).flatten()\n","        metrics_report = metrics.classification_report(true_vals,preds_flat, output_dict=True)\n","        lg.info(metrics_report)\n","        \n","        return metrics_report\n","    \n","\n","    def training_model(self, model, model_name, dataloader_train, dataloader_validation, epochs, scheduler, optimizer, device, token):\n","        seed_val = 1\n","        random.seed(seed_val)\n","        np.random.seed(seed_val)\n","        torch.manual_seed(seed_val)\n","        torch.cuda.manual_seed_all(seed_val)\n","        epoch_array = []\n","        f1_array = []\n","        train_loss_array = []\n","        val_loss_array = []\n","\n","        for epoch in tqdm(range(1, epochs+1)):\n","\n","            model.train()\n","\n","            loss_train_total = 0\n","\n","            progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","            for batch in progress_bar:\n","\n","                model.zero_grad()\n","\n","                batch = tuple(b.to(device) for b in batch)\n","\n","                inputs = {'input_ids':      batch[0],\n","                          'attention_mask': batch[1],\n","                          'labels':         batch[2],\n","                         }       \n","\n","                outputs = model(**inputs)\n","\n","                loss = outputs[0]\n","                loss_train_total += loss.item()\n","                loss.backward()\n","\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","                optimizer.step()\n","                scheduler.step()\n","\n","                progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","\n","\n","            torch.save(model.state_dict(),f'{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epoch}.model')\n","            model.save_pretrained(f\"{MODEL_SAVE_PATH}/token{token}_model_data_{model_name}_epoch_{epoch}\")\n","            tqdm.write(f'\\nEpoch {epoch}')\n","            print(f'\\nEpoch {epoch}')\n","            lg.info(f'\\nEpoch {epoch}')\n","\n","            loss_train_avg = loss_train_total/len(dataloader_train)            \n","            tqdm.write(f'Training loss: {loss_train_avg}')\n","            lg.info(f'Training loss: {loss_train_avg}')\n","\n","            val_loss, predictions, true_vals = Model_BERT().evaluate(model, dataloader_validation, device)\n","            val_f1 = Model_BERT().f1_score_func(predictions, true_vals)\n","            tqdm.write(f'Validation loss: {val_loss}')\n","            print(f'Validation loss: {val_loss}')\n","            lg.info(f'Validation loss: {val_loss}')\n","            \n","            tqdm.write(f'F1 Score (Weighted/Binary): {val_f1}')\n","            print(f'F1 Score (Weighted/Binary): {val_f1}')\n","            lg.info(f'F1 Score (Weighted/Binary): {val_f1}')\n","            \n","            epoch_array.append(epoch)\n","            f1_array.append(val_f1)\n","            val_loss_array.append(val_loss)\n","            train_loss_array.append(loss_train_avg)\n","\n","        return(epoch_array, f1_array, val_loss_array, train_loss_array)\n","    \n","    def read_df(self, df):\n","        df['label_num'] = df.label.replace(LABEL_DICT)\n","\n","        X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n","                                                  df.label_num.values, \n","                                                  test_size=0.4, \n","                                                  random_state=42, \n","                                                  stratify=df.label.values)\n","        df['data_type'] = ['not_set']*df.shape[0]\n","        df.loc[X_train, 'data_type'] = 'train'\n","        df.loc[X_val, 'data_type'] = 'val'\n","        \n","        return(df)\n","\n","    def call_setup(self, model_name, df, token, epochs):\n","        df = Model_BERT().read_df(df)\n","        model_path = Model_BERT().model_path_def(model_name)\n","        print(model_path)\n","        dataset_train, dataset_val = Model_BERT().tokenizer_model(model_path, df, token)\n","        model, dataloader_train, dataloader_val, epochs, scheduler, optimizer, device = Model_BERT().setup_model(model_path, dataset_train, dataset_val, epochs)\n","        epoch_array, f1_array, val_loss_array, train_loss_array = Model_BERT().training_model(model, model_name, dataloader_train, dataloader_val, epochs, scheduler, optimizer, device, token)\n","        df_performa = pd.DataFrame()\n","        df_performa[\"epoch\"] = epoch_array\n","        df_performa[\"f1\"] = f1_array\n","        df_performa[\"val_loss\"] = val_loss_array\n","        df_performa[\"train_loss\"] = train_loss_array\n","        metrics_report = Model_BERT().results(model_path,model_name,epochs,dataloader_val, device, token)\n","        lg.info(f'Metric Report Call Setup: {metrics_report}')\n","        \n","        return metrics_report, df_performa"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def cleaning(df,column):\n","    # Remove urls\n","    df.loc[:,column] = df[column].replace(r'https?:\\/\\/.*?[\\s+]', ' ', regex=True)\n","    # Remove urls without https?\n","    df.loc[:,column] = df[column].replace(r'www.*?[\\s+]', ' ', regex=True)\n","    # Remove email address\n","    df.loc[:,column] = df[column].replace(r'(?P<email_address>[\\w\\.-]+@[\\w\\.-]+\\.[\\w]+)', ' ', regex=True)\n","    \n","    df.loc[:,column] = df[column].str.replace('º',' ')\n","    df.loc[:,column] = df[column].str.replace('ª',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('1',' ')\n","    df.loc[:,column] = df[column].str.replace('2',' ')\n","    df.loc[:,column] = df[column].str.replace('3',' ')\n","    df.loc[:,column] = df[column].str.replace('4',' ')\n","    df.loc[:,column] = df[column].str.replace('5',' ')\n","    df.loc[:,column] = df[column].str.replace('6',' ')\n","    df.loc[:,column] = df[column].str.replace('7',' ')\n","    df.loc[:,column] = df[column].str.replace('8',' ')\n","    df.loc[:,column] = df[column].str.replace('9',' ')\n","    df.loc[:,column] = df[column].str.replace('0',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('/',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('\\r',' ')\n","    df.loc[:,column] = df[column].str.replace('\\n',' ')\n","    df.loc[:,column] = df[column].str.replace('\\t',' ')\n","    df.loc[:,column] = df[column].str.replace('\\\\',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('-',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('–',' ')\n","    df.loc[:,column] = df[column].str.replace('“',' ')\n","    df.loc[:,column] = df[column].str.replace('”',' ')\n","    df.loc[:,column] = df[column].str.replace('’',' ')\n","    df.loc[:,column] = df[column].str.replace('_',' ')\n","    df.loc[:,column] = df[column].str.replace('.',' ')\n","    df.loc[:,column] = df[column].str.replace(',',' ')\n","    df.loc[:,column] = df[column].str.replace('|',' ')\n","    df.loc[:,column] = df[column].str.replace('=',' ')\n","    df.loc[:,column] = df[column].str.replace('@',' ')\n","    df.loc[:,column] = df[column].str.replace('$',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('°',' ')\n","    df.loc[:,column] = df[column].str.replace('§',' ')\n","    df.loc[:,column] = df[column].str.replace('•',' ')\n","    df.loc[:,column] = df[column].str.replace('▪',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('%',' ')\n","    df.loc[:,column] = df[column].str.replace('&',' ')\n","    df.loc[:,column] = df[column].str.replace('*',' ')\n","    df.loc[:,column] = df[column].str.replace('+',' ')\n","    df.loc[:,column] = df[column].str.replace(':',' ')\n","    df.loc[:,column] = df[column].str.replace(';',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('!',' ')\n","    df.loc[:,column] = df[column].str.replace('?',' ')\n","    df.loc[:,column] = df[column].str.replace('#',' ')\n","    df.loc[:,column] = df[column].str.replace('\\'',' ')\n","    df.loc[:,column] = df[column].str.replace('\"',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('<',' ')\n","    df.loc[:,column] = df[column].str.replace('>',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('(',' ')\n","    df.loc[:,column] = df[column].str.replace(')',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('{',' ')\n","    df.loc[:,column] = df[column].str.replace('}',' ')\n","\n","    df.loc[:,column] = df[column].str.replace('[',' ')\n","    df.loc[:,column] = df[column].str.replace(']',' ')\n","\n","    # Remove the same character repeated more than twice\n","    df.loc[:,column] = df[column].replace(r'([a-z])\\1{2,}', ' ', regex=True)\n","    \n","    # To replace more than one white space by only one white space\n","    df.loc[:,column] = df[column].replace(r'\\s+', ' ', regex=True)\n","\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Selecting the Departments</h3>"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-01 16:33:21.915 | INFO     | __main__:<module>:4 - boards_list: ['DPT_25', 'DPT_3', 'DPT_2']\n"]}],"source":["boards = data_relevant['department']\n","# Getting the 6 most populated boards\n","boards_list = list(boards.unique())[:DEPARTMENTS_QUANTITY_TO_TRAIN]\n","lg.info(f\"boards_list: {boards_list}\")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["df_modelagem_init = pd.concat([data_irrelevant, data_relevant])"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["df_modelagem_init['class'] = df_modelagem_init['class'].astype(str)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["df_modelagem_init = df_modelagem_init.rename(columns={\"class\":\"label\"})"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["label                   704\n","department              704\n","entry_date              704\n","general_id              704\n","normative_identifier    704\n","publication_date        704\n","regulatory_authority    704\n","subject                 704\n","subject_length          704\n","subject_unique_words    704\n","subject_words           704\n","text                    704\n","text_length             704\n","text_unique_words       704\n","text_words              704\n","type                    704\n","unique_document_id      704\n","url                     704\n","dtype: int64"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["df_modelagem_init.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["for department in boards_list:\n","    lg.debug(f\"Department: {department}\")\n","    df_modelagem = df_modelagem_init[df_modelagem_init.department == department]\n","\n","    df_modelagem = df_modelagem.dropna()\n","    df_modelagem = df_modelagem.reset_index(drop=True)\n","    df_modelagem = df_modelagem.rename(columns={\"text\":\"content\"})\n","\n","    df_modelagem = cleaning(df_modelagem,\"content\")\n","\n","    new_content = []\n","    for texto in df_modelagem.content:\n","        new_content.append(texto.replace(\"[BUSINESS NEED]\", \"\"))\n","    df_modelagem[\"new_content\"] = new_content\n","    \n","    LABEL_DICT = {'0': 0, '1': 1}\n","\n","    MODEL_SAVE_PATH = \"notebooks/testes/scoring\"\n","    BERTIMBAU_BASE = \"datasets/BERTIMBAU_BASE\"\n","    BERTIMBAU_TOKENIZER = \"tokenizer/BERTimbau_Tokenizer\"\n","\n","    MODEL_PATH = BERTIMBAU_BASE\n","    MODEL_PATH_NEW = BERTIMBAU_BASE\n","\n","    tokenizer = BertTokenizer.from_pretrained(BERTIMBAU_TOKENIZER, do_lower_case=True)\n","\n","    lg.debug(f\"Department count samples: {df_modelagem.count()}\")\n","    lg.debug(f\"Department count samples class 1: {df_modelagem[df_modelagem.label == '1'].count()}\")\n","    lg.debug(f\"Department count samples class 0: {df_modelagem[df_modelagem.label == '0'].count()}\")\n","    \n","\n","    Model_BERT().call_setup(\"BERTIMBAU_BASE\", df_modelagem, 512, 5)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>The output result is in the next cell. It was copied from the log file.</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2023-10-10 10:30:47.737 | INFO     | __main__:<module>:5 - \n","\n","# ####################################### NEW EXECUTION #######################################\n","\n","\n","# 2023-10-10 10:30:47.738 | INFO     | __main__:<module>:6 - Processors (cores) available: 38\n","# 2023-10-10 10:30:57.737 | INFO     | __main__:<module>:4 - boards_list: ['DPT_25', 'DPT_3', 'DPT_2']\n","# 2023-10-10 10:30:57.788 | DEBUG    | __main__:<module>:2 - Department: DPT_25\n","# 2023-10-10 10:30:58.299 | DEBUG    | __main__:<module>:37 - Department count samples: label                   208\n","# department              208\n","# entry_date              208\n","# general_id              208\n","# normative_identifier    208\n","# publication_date        208\n","# regulatory_authority    208\n","# subject                 208\n","# subject_length          208\n","# subject_unique_words    208\n","# subject_words           208\n","# content                 208\n","# text_length             208\n","# text_unique_words       208\n","# text_words              208\n","# type                    208\n","# unique_document_id      208\n","# url                     208\n","# new_content             208\n","# dtype: int64\n","# 2023-10-10 10:30:58.303 | DEBUG    | __main__:<module>:38 - Department count samples class 1: label                   104\n","# department              104\n","# entry_date              104\n","# general_id              104\n","# normative_identifier    104\n","# publication_date        104\n","# regulatory_authority    104\n","# subject                 104\n","# subject_length          104\n","# subject_unique_words    104\n","# subject_words           104\n","# content                 104\n","# text_length             104\n","# text_unique_words       104\n","# text_words              104\n","# type                    104\n","# unique_document_id      104\n","# url                     104\n","# new_content             104\n","# dtype: int64\n","# 2023-10-10 10:30:58.305 | DEBUG    | __main__:<module>:39 - Department count samples class 0: label                   104\n","# department              104\n","# entry_date              104\n","# general_id              104\n","# normative_identifier    104\n","# publication_date        104\n","# regulatory_authority    104\n","# subject                 104\n","# subject_length          104\n","# subject_unique_words    104\n","# subject_words           104\n","# content                 104\n","# text_length             104\n","# text_unique_words       104\n","# text_words              104\n","# type                    104\n","# unique_document_id      104\n","# url                     104\n","# new_content             104\n","# dtype: int64\n","# 2023-10-10 10:31:20.724 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-10 10:31:20.725 | INFO     | __main__:training_model:214 - Training loss: 0.6965916454792023\n","# 2023-10-10 10:31:21.485 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6993502577145895, [[0.19235902 0.11708909]\n","\n","# 2023-10-10 10:31:21.489 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.16949152542372883\n","# 2023-10-10 10:31:21.490 | INFO     | __main__:training_model:220 - Validation loss: 0.6993502577145895\n","# 2023-10-10 10:31:21.491 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.16949152542372883\n","# 2023-10-10 10:31:27.066 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-10 10:31:27.068 | INFO     | __main__:training_model:214 - Training loss: 0.6985060423612595\n","# 2023-10-10 10:31:27.830 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6988730033238729, [[0.18783389 0.11924584]\n","\n","# 2023-10-10 10:31:27.833 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.19354838709677416\n","# 2023-10-10 10:31:27.834 | INFO     | __main__:training_model:220 - Validation loss: 0.6988730033238729\n","# 2023-10-10 10:31:27.835 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.19354838709677416\n","# 2023-10-10 10:31:33.383 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-10 10:31:33.385 | INFO     | __main__:training_model:214 - Training loss: 0.6937734484672546\n","# 2023-10-10 10:31:34.148 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.698234498500824, [[ 0.17943902  0.12156092]\n","\n","# 2023-10-10 10:31:34.150 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.2222222222222222\n","# 2023-10-10 10:31:34.152 | INFO     | __main__:training_model:220 - Validation loss: 0.698234498500824\n","# 2023-10-10 10:31:34.153 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.2222222222222222\n","# 2023-10-10 10:31:39.681 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-10 10:31:39.682 | INFO     | __main__:training_model:214 - Training loss: 0.6967955827713013\n","# 2023-10-10 10:31:40.448 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6974149346351624, [[ 0.16675785  0.12218992]\n","\n","# 2023-10-10 10:31:40.452 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.2985074626865672\n","# 2023-10-10 10:31:40.453 | INFO     | __main__:training_model:220 - Validation loss: 0.6974149346351624\n","# 2023-10-10 10:31:40.453 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.2985074626865672\n","# 2023-10-10 10:31:46.255 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-10 10:31:46.257 | INFO     | __main__:training_model:214 - Training loss: 0.7008830606937408\n","# 2023-10-10 10:31:47.025 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6961301763852438, [[ 0.14382999  0.12268669]\n","\n","# 2023-10-10 10:31:47.028 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.37500000000000006\n","# 2023-10-10 10:31:47.030 | INFO     | __main__:training_model:220 - Validation loss: 0.6961301763852438\n","# 2023-10-10 10:31:47.031 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.37500000000000006\n","# 2023-10-10 10:31:49.363 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6961301763852438, [[ 0.14382999  0.12268669]\n"," \n","# 2023-10-10 10:31:49.365 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-10 10:31:49.366 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 19/42\n","# 2023-10-10 10:31:49.367 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.4523809523809524\n","\n","# 2023-10-10 10:31:49.367 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-10 10:31:49.368 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 15/42\n","# 2023-10-10 10:31:49.369 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.35714285714285715\n","\n","# 2023-10-10 10:31:49.376 | INFO     | __main__:results:157 - {'0': {'precision': 0.41304347826086957, 'recall': 0.4523809523809524, 'f1-score': 0.4318181818181818, 'support': 42}, '1': {'precision': 0.39473684210526316, 'recall': 0.35714285714285715, 'f1-score': 0.37500000000000006, 'support': 42}, 'accuracy': 0.40476190476190477, 'macro avg': {'precision': 0.40389016018306634, 'recall': 0.40476190476190477, 'f1-score': 0.40340909090909094, 'support': 84}, 'weighted avg': {'precision': 0.40389016018306634, 'recall': 0.40476190476190477, 'f1-score': 0.40340909090909094, 'support': 84}}\n","# 2023-10-10 10:31:49.378 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.41304347826086957, 'recall': 0.4523809523809524, 'f1-score': 0.4318181818181818, 'support': 42}, '1': {'precision': 0.39473684210526316, 'recall': 0.35714285714285715, 'f1-score': 0.37500000000000006, 'support': 42}, 'accuracy': 0.40476190476190477, 'macro avg': {'precision': 0.40389016018306634, 'recall': 0.40476190476190477, 'f1-score': 0.40340909090909094, 'support': 84}, 'weighted avg': {'precision': 0.40389016018306634, 'recall': 0.40476190476190477, 'f1-score': 0.40340909090909094, 'support': 84}}\n","# 2023-10-10 10:31:49.381 | DEBUG    | __main__:<module>:2 - Department: DPT_3\n","# 2023-10-10 10:31:52.283 | DEBUG    | __main__:<module>:37 - Department count samples: label                   392\n","# department              392\n","# entry_date              392\n","# general_id              392\n","# normative_identifier    392\n","# publication_date        392\n","# regulatory_authority    392\n","# subject                 392\n","# subject_length          392\n","# subject_unique_words    392\n","# subject_words           392\n","# content                 392\n","# text_length             392\n","# text_unique_words       392\n","# text_words              392\n","# type                    392\n","# unique_document_id      392\n","# url                     392\n","# new_content             392\n","# dtype: int64\n","# 2023-10-10 10:31:52.286 | DEBUG    | __main__:<module>:38 - Department count samples class 1: label                   196\n","# department              196\n","# entry_date              196\n","# general_id              196\n","# normative_identifier    196\n","# publication_date        196\n","# regulatory_authority    196\n","# subject                 196\n","# subject_length          196\n","# subject_unique_words    196\n","# subject_words           196\n","# content                 196\n","# text_length             196\n","# text_unique_words       196\n","# text_words              196\n","# type                    196\n","# unique_document_id      196\n","# url                     196\n","# new_content             196\n","# dtype: int64\n","# 2023-10-10 10:31:52.290 | DEBUG    | __main__:<module>:39 - Department count samples class 0: label                   196\n","# department              196\n","# entry_date              196\n","# general_id              196\n","# normative_identifier    196\n","# publication_date        196\n","# regulatory_authority    196\n","# subject                 196\n","# subject_length          196\n","# subject_unique_words    196\n","# subject_words           196\n","# content                 196\n","# text_length             196\n","# text_unique_words       196\n","# text_words              196\n","# type                    196\n","# unique_document_id      196\n","# url                     196\n","# new_content             196\n","# dtype: int64\n","# 2023-10-10 10:32:48.337 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-10 10:32:48.339 | INFO     | __main__:training_model:214 - Training loss: 0.6908790990710258\n","# 2023-10-10 10:32:49.758 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.7044742604096731, [[ 0.15235686  0.08747568]\n"," \n","# 2023-10-10 10:32:49.762 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.09411764705882351\n","# 2023-10-10 10:32:49.763 | INFO     | __main__:training_model:220 - Validation loss: 0.7044742604096731\n","# 2023-10-10 10:32:49.765 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.09411764705882351\n","# 2023-10-10 10:32:58.467 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-10 10:32:58.470 | INFO     | __main__:training_model:214 - Training loss: 0.6866002678871155\n","# 2023-10-10 10:32:59.896 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6963733931382498, [[ 0.13420327  0.1274321 ]\n"," \n","# 2023-10-10 10:32:59.900 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.35714285714285715\n","# 2023-10-10 10:32:59.901 | INFO     | __main__:training_model:220 - Validation loss: 0.6963733931382498\n","# 2023-10-10 10:32:59.902 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.35714285714285715\n","# 2023-10-10 10:33:08.571 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-10 10:33:08.572 | INFO     | __main__:training_model:214 - Training loss: 0.6749535351991653\n","# 2023-10-10 10:33:10.003 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6873311400413513, [[ 0.11063756  0.16893572]\n"," \n","# 2023-10-10 10:33:10.007 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.5342465753424658\n","# 2023-10-10 10:33:10.009 | INFO     | __main__:training_model:220 - Validation loss: 0.6873311400413513\n","# 2023-10-10 10:33:10.010 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.5342465753424658\n","# 2023-10-10 10:33:18.707 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-10 10:33:18.708 | INFO     | __main__:training_model:214 - Training loss: 0.6750572621822357\n","# 2023-10-10 10:33:20.147 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6758909722169241, [[ 0.082546    0.22458252]\n"," \n","# 2023-10-10 10:33:20.150 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.6101694915254238\n","# 2023-10-10 10:33:20.155 | INFO     | __main__:training_model:220 - Validation loss: 0.6758909722169241\n","# 2023-10-10 10:33:20.156 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.6101694915254238\n","# 2023-10-10 10:33:28.937 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-10 10:33:28.938 | INFO     | __main__:training_model:214 - Training loss: 0.661759041249752\n","# 2023-10-10 10:33:30.380 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6659130950768789, [[ 0.07391369  0.2572748 ]\n"," \n","# 2023-10-10 10:33:30.383 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.623529411764706\n","# 2023-10-10 10:33:30.385 | INFO     | __main__:training_model:220 - Validation loss: 0.6659130950768789\n","# 2023-10-10 10:33:30.385 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.623529411764706\n","# 2023-10-10 10:33:33.174 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6659130950768789, [[ 0.07391369  0.2572748 ]\n"," \n","# 2023-10-10 10:33:33.176 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-10 10:33:33.177 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 40/79\n","# 2023-10-10 10:33:33.177 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.5063291139240507\n","\n","# 2023-10-10 10:33:33.178 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-10 10:33:33.179 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 53/78\n","# 2023-10-10 10:33:33.179 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.6794871794871795\n","\n","# 2023-10-10 10:33:33.187 | INFO     | __main__:results:157 - {'0': {'precision': 0.6153846153846154, 'recall': 0.5063291139240507, 'f1-score': 0.5555555555555556, 'support': 79}, '1': {'precision': 0.5760869565217391, 'recall': 0.6794871794871795, 'f1-score': 0.623529411764706, 'support': 78}, 'accuracy': 0.5923566878980892, 'macro avg': {'precision': 0.5957357859531773, 'recall': 0.5929081467056151, 'f1-score': 0.5895424836601308, 'support': 157}, 'weighted avg': {'precision': 0.5958609377329953, 'recall': 0.5923566878980892, 'f1-score': 0.5893260064110571, 'support': 157}}\n","# 2023-10-10 10:33:33.189 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.6153846153846154, 'recall': 0.5063291139240507, 'f1-score': 0.5555555555555556, 'support': 79}, '1': {'precision': 0.5760869565217391, 'recall': 0.6794871794871795, 'f1-score': 0.623529411764706, 'support': 78}, 'accuracy': 0.5923566878980892, 'macro avg': {'precision': 0.5957357859531773, 'recall': 0.5929081467056151, 'f1-score': 0.5895424836601308, 'support': 157}, 'weighted avg': {'precision': 0.5958609377329953, 'recall': 0.5923566878980892, 'f1-score': 0.5893260064110571, 'support': 157}}\n","# 2023-10-10 10:33:33.192 | DEBUG    | __main__:<module>:2 - Department: DPT_2\n","# 2023-10-10 10:33:33.510 | DEBUG    | __main__:<module>:37 - Department count samples: label                   104\n","# department              104\n","# entry_date              104\n","# general_id              104\n","# normative_identifier    104\n","# publication_date        104\n","# regulatory_authority    104\n","# subject                 104\n","# subject_length          104\n","# subject_unique_words    104\n","# subject_words           104\n","# content                 104\n","# text_length             104\n","# text_unique_words       104\n","# text_words              104\n","# type                    104\n","# unique_document_id      104\n","# url                     104\n","# new_content             104\n","# dtype: int64\n","# 2023-10-10 10:33:33.513 | DEBUG    | __main__:<module>:38 - Department count samples class 1: label                   52\n","# department              52\n","# entry_date              52\n","# general_id              52\n","# normative_identifier    52\n","# publication_date        52\n","# regulatory_authority    52\n","# subject                 52\n","# subject_length          52\n","# subject_unique_words    52\n","# subject_words           52\n","# content                 52\n","# text_length             52\n","# text_unique_words       52\n","# text_words              52\n","# type                    52\n","# unique_document_id      52\n","# url                     52\n","# new_content             52\n","# dtype: int64\n","# 2023-10-10 10:33:33.516 | DEBUG    | __main__:<module>:39 - Department count samples class 0: label                   52\n","# department              52\n","# entry_date              52\n","# general_id              52\n","# normative_identifier    52\n","# publication_date        52\n","# regulatory_authority    52\n","# subject                 52\n","# subject_length          52\n","# subject_unique_words    52\n","# subject_words           52\n","# content                 52\n","# text_length             52\n","# text_unique_words       52\n","# text_words              52\n","# type                    52\n","# unique_document_id      52\n","# url                     52\n","# new_content             52\n","# dtype: int64\n","# 2023-10-10 10:33:43.032 | INFO     | __main__:training_model:210 - \n","# Epoch 1\n","# 2023-10-10 10:33:43.033 | INFO     | __main__:training_model:214 - Training loss: 0.6881098747253418\n","# 2023-10-10 10:33:43.424 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6997461318969727, [[ 0.30694127  0.08413929]\n"," \n","# 2023-10-10 10:33:43.427 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.0909090909090909\n","# 2023-10-10 10:33:43.429 | INFO     | __main__:training_model:220 - Validation loss: 0.6997461318969727\n","# 2023-10-10 10:33:43.430 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.0909090909090909\n","# 2023-10-10 10:33:47.212 | INFO     | __main__:training_model:210 - \n","# Epoch 2\n","# 2023-10-10 10:33:47.214 | INFO     | __main__:training_model:214 - Training loss: 0.6941970884799957\n","# 2023-10-10 10:33:47.606 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6986801624298096, [[ 0.30528542  0.08728919]\n"," \n","# 2023-10-10 10:33:47.609 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.17391304347826084\n","# 2023-10-10 10:33:47.611 | INFO     | __main__:training_model:220 - Validation loss: 0.6986801624298096\n","# 2023-10-10 10:33:47.612 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.17391304347826084\n","# 2023-10-10 10:33:51.739 | INFO     | __main__:training_model:210 - \n","# Epoch 3\n","# 2023-10-10 10:33:51.741 | INFO     | __main__:training_model:214 - Training loss: 0.69303297996521\n","# 2023-10-10 10:33:52.131 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6972529292106628, [[ 0.30319765  0.09119336]\n"," \n","# 2023-10-10 10:33:52.134 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.17391304347826084\n","# 2023-10-10 10:33:52.135 | INFO     | __main__:training_model:220 - Validation loss: 0.6972529292106628\n","# 2023-10-10 10:33:52.136 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.17391304347826084\n","# 2023-10-10 10:33:56.043 | INFO     | __main__:training_model:210 - \n","# Epoch 4\n","# 2023-10-10 10:33:56.045 | INFO     | __main__:training_model:214 - Training loss: 0.692831426858902\n","# 2023-10-10 10:33:56.436 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6951631903648376, [[ 0.30027413  0.09689736]\n"," \n","# 2023-10-10 10:33:56.439 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.17391304347826084\n","# 2023-10-10 10:33:56.441 | INFO     | __main__:training_model:220 - Validation loss: 0.6951631903648376\n","# 2023-10-10 10:33:56.442 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.17391304347826084\n","# 2023-10-10 10:34:00.359 | INFO     | __main__:training_model:210 - \n","# Epoch 5\n","# 2023-10-10 10:34:00.361 | INFO     | __main__:training_model:214 - Training loss: 0.6801402270793915\n","# 2023-10-10 10:34:00.751 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6930978894233704, [[ 0.29772893  0.10173518]\n"," \n","# 2023-10-10 10:34:00.754 | INFO     | __main__:f1_score_func:85 - f1_score_binary: 0.3076923076923077\n","# 2023-10-10 10:34:00.755 | INFO     | __main__:training_model:220 - Validation loss: 0.6930978894233704\n","# 2023-10-10 10:34:00.756 | INFO     | __main__:training_model:224 - F1 Score (Weighted/Binary): 0.3076923076923077\n","# 2023-10-10 10:34:02.472 | INFO     | __main__:evaluate:138 - loss_val_avg, predictions, true_vals: 0.6930978894233704, [[ 0.29772893  0.10173518]\n"," \n","# 2023-10-10 10:34:02.473 | INFO     | __main__:accuracy_per_class:101 - Class: 0\n","# 2023-10-10 10:34:02.474 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 20/21\n","# 2023-10-10 10:34:02.475 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.9523809523809523\n","\n","# 2023-10-10 10:34:02.476 | INFO     | __main__:accuracy_per_class:101 - Class: 1\n","# 2023-10-10 10:34:02.476 | INFO     | __main__:accuracy_per_class:102 - Accuracy: 4/21\n","# 2023-10-10 10:34:02.477 | INFO     | __main__:accuracy_per_class:103 - % Accuracy: 0.19047619047619047\n","\n","# 2023-10-10 10:34:02.484 | INFO     | __main__:results:157 - {'0': {'precision': 0.5405405405405406, 'recall': 0.9523809523809523, 'f1-score': 0.6896551724137931, 'support': 21}, '1': {'precision': 0.8, 'recall': 0.19047619047619047, 'f1-score': 0.3076923076923077, 'support': 21}, 'accuracy': 0.5714285714285714, 'macro avg': {'precision': 0.6702702702702703, 'recall': 0.5714285714285714, 'f1-score': 0.49867374005305043, 'support': 42}, 'weighted avg': {'precision': 0.6702702702702703, 'recall': 0.5714285714285714, 'f1-score': 0.49867374005305043, 'support': 42}}\n","# 2023-10-10 10:34:02.486 | INFO     | __main__:call_setup:260 - Metric Report Call Setup: {'0': {'precision': 0.5405405405405406, 'recall': 0.9523809523809523, 'f1-score': 0.6896551724137931, 'support': 21}, '1': {'precision': 0.8, 'recall': 0.19047619047619047, 'f1-score': 0.3076923076923077, 'support': 21}, 'accuracy': 0.5714285714285714, 'macro avg': {'precision': 0.6702702702702703, 'recall': 0.5714285714285714, 'f1-score': 0.49867374005305043, 'support': 42}, 'weighted avg': {'precision': 0.6702702702702703, 'recall': 0.5714285714285714, 'f1-score': 0.49867374005305043, 'support': 42}}\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
